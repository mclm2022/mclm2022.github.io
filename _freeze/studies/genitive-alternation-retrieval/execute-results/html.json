{
  "hash": "c905243ee584b227093bfb0b770cb15d",
  "result": {
    "markdown": "---\ntitle: \"Genitive Alternation I: Retrieval\"\n---\n\n\nThis is the first part of a variation study focusing on the genitive alternation in English, using the Brown corpus. This part focuses on retrieving observations of the alternation, whereas the second part will illustrate the analysis with conditional inference trees and mixed-effects logistic regression. One of the reasons to split the analysis in two is that, more often than not, between retrieval and analysis there is an additional step of manual cleaning or annotation of the dataset.\n\n\n\n\n\n# Setup\n\nFor this study we need to activate the packages `{tidyverse}` and `{mclm}`. We will also use `kableExtra()` to print some tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(mclm)\nlibrary(kableExtra)\n```\n:::\n\n\nWe'll collect the files from the Brown corpus. To replicate this code, adjust the path to wherever you stored your copy of the corpus. In this case, we also add a `keep_re()` call to capture the pattern shared by all corpus files and not by metadata files such as \"CONTENTS\" and \"README\".[For more information on the Brown corpus, such as the components and tagset, see the Wikipedia documentation: https://en.wikipedia.org/wiki/Brown_Corpus.]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrown_fnames <- get_fnames(corpus_folder) %>% \n  keep_re(\"/c[a-z][0-9]{2}\")\nprint(brown_fnames, n = 10, hide_path = corpus_folder)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFilename collection of length 500\n   filename\n   --------\n 1     ca01\n 2     ca02\n 3     ca03\n 4     ca04\n 5     ca05\n 6     ca06\n 7     ca07\n 8     ca08\n 9     ca09\n10     ca10\n...\n```\n:::\n:::\n\n\n## POS tags\n\nThe text in this corpus looks as follows, with word forms followed by a part-of-speech tag, with a slash in between.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at\ninvestigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/\nvbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd\nplace/nn ./.\n```\n:::\n:::\n\n\nSome of the POS tags of Brown are of particular importance for this case study.\n\nat\n\n:   article, e.g. *the/at*\n\nin\n\n:   preposition, e.g. *of/in*\n\njj\n\n:   adjective, e.g. *recent/jj*\n\nnn\n\n:   common noun, e.g. *year/nn*\n\nnp\n\n:   proper noun, e.g. *Atlanta/np*\n\n-tl\n\n:   (suffix to a POS tag) title or part of title, e.g. Sen./nn-tl George/np Parkhouse/np\n\n\\$\n\n:   (suffix to a POS tag) genitive marker (since a token ending in *'s* will be treated as one token), e.g. *the/at major's/nn\\$ occupation/nn, Atlanta's/np\\$ recent/jj primary/nn*\n\n# Data retrieval\n\nOur goal is to obtain the attestations of the genitive alternation in the Brown corpus, e.g. examples of *the student's idea* and *the idea of the student*. In this alternation, the main elements we are interested in are called \"Possessor\" and \"Possessed\", because the prototypical situation of the genitive is that of possession. However, the terminology can be misleading, because this is not the only meaning of the genitive constructions. For example, in *The car's owner*, *car* takes the role of Possessor and *owner* that of Possessed.\n\nAn alternation study aims to describe the aspects of language use that favor or disfavor one variant of the alternation against the other. This translates to studies where the alternation itself, e.g. where an *s* form or an *of* form is used, becomes the response variable, and different characteristics of the context become predictors or regressors. In this study, we'll capture the following predictors:\n\npossessor_type\n\n:    Whether the role of the Possessor is filled by a common noun or a proper noun\n\npossessor_size\n\n:   The size of the Possessor slot, in characters\n\npossessed_size\n\n:   The size of the Possessed slot, in characters\n\nsize_difference\n\n:   The difference between the size of the possessor and that of the possessed\n\nThe reason for taking the size of the constituents, i.e. Possessor and Possessed, is the theory within linguistics that speakers try to push longer constituents towards the end. In the genitive alternation, in which each variant has a different word order, this becomes relevant. Concretely, in the *s* variant we have the Possessor before the Possessed (*The student's idea*), whereas in the *of* variant we have the Possessed before the Possessor (*The idea of the student*). If we indeed tend to push longer constituents towards the end, a long Possessor such as *the keen and insightful student* would favor the *of variant* (*The idea of the keen and insightful student*) rather than the *s* variant (*The keen and insightful student's idea*).\n\nIn practice, we will also transform the sizes to their logarithm, in order to lessen the impact of extremely long constituents.\n\nThe strategy of data retrieval consists of four queries with non-overlapping results, aimed at collecting four different patterns:\n\n-   of-genitive with common nouns\n\n-   of-genitive with proper nouns\n\n-   s-genitive with common nouns\n\n-   s-genitive with proper nouns\n\nFor each of these queries, we will:\n\n1.  Collect the observations with `mclm::conc()`, generating a concordance.\n2.  Add columns with the values of `gen_type` (our response variable) and `possessor_type`, since they are the same for all observations in that query.\n3.  Extract the `possessed` and `possessor` based on their position in the query. For that purpose, the regular expressions used to query the corpus include capturing groups surrounding each of the constituents.\n\nThis will be achieved with the following lines of code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncd <- brown_fnames %>% \n  conc(pattern) %>%  # whatever regex pattern we have defined\n  mutate(\n    gen_type = \"of\",                                     # or \"s\"\n    possessor_type = \"common\",                           # or proper\n    possessed = re_replace_first(match, pattern, \"\\\\1\"), # or \\\\2 for s-genitive\n    possessor = re_replace_first(match, pattern, \"\\\\2\")  # or \\\\1 for of-genitive\n  )\n```\n:::\n\n\n4.  Once we have more than one concordance, we can merge them with `merge_conc()`.\n\n:::{.callout-caution collapse=\"true\"}\n\n## Variable names\n\nThe first concordance will be stored in a variable called `cd`, to which we will merge each new concordance, called `cd_new`. Alternatively, you could name each concordance differently and then merge them into a larger concordance `conc_merged`, for example.\n\nThe first approach has the advantage of avoiding duplicate objects and using more memory than necessary. `cd_new` is constantly rewritten and, at the end, you only have one large concordance `cd` and a small `cd_new` concordance with the latest query. In contrast, with the second approach you end up with four small concordances and one large one, and their contents are duplicated.\n\nThe second approach makes sense if you need to keep the datasets separate. When you're writing a long script or processing a dataset in different ways, overwriting a variable may bring confusion, as you forget the contents of the variable at any given time.\n\nThink about this in your own analyses.\n\n:::\n\n## Of-genitive with common nouns\n\nIn the first query we will retrieve the attestations of the *of*-genitive with common nouns, e.g. *the idea of the student*.\n\n### Regular expression\n\nAs a first step, we construct a regular expression that will match, in the non-tokenized corpus, the sequence we are interested in, and we'll store it in a variable `pattern`. Notice that we use a raw string (preceded with `r` and, within the quotation marks, surrounded by two hyphens and a square bracket) and that we flag the regular expression with an `x` and an `i`. The `x` allows us to insert spaces and line breaks for more readability (free-spacing mode), and the `i` makes the search case insensitive.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\npattern <- r\"--[(?xi)\n          \\b         the / at          \\s+\n          ( (?:  [^\\s/]+ / jj  [^\\s]*  \\s+ )*\n            (?:  [^\\s/]+ / nn  [^\\s]*  \\s+ )*\n                 [^\\s/]+ / nn  [^\\s]*\n          )                            \\s+\n                      of / in          \\s+\n                     the / at          \\s+\n          ( (?:  [^\\s/]+ / jj  [^\\s]*  \\s+ )*\n            (?:  [^\\s/]+ / nn  [^\\s]*  \\s+ )*\n                 [^\\s/]+ / nn  [^\\s$]* \n          )                            \\s    \n]--\"\n```\n:::\n\n\nIn line 2 we have a `\\b`, followed by the string *the/at*, followed by `\\s+`. This means that we want the literal string *the/at* preceded by a word boundary and followed by one or more whitespace characters. A word boundary at the beginning covers whitespace characters, punctuation marks and even the beginning of the text.\n\nLines 3-5 and 9-11 are surrounded by parentheses, turning them into capturing groups. Later, when we want to extract the Possessed and Possessor from the match, we can ask for the text matching each of the capturing groups.\n\nWithin the capturing groups we have non-capturing groups, marked by parentheses and `?:` at the beginning. If we didn't add `?:` at the beginning, they would be included in the numbering of the capturing groups and we wouldn't know for sure which number belongs to the full Possessed and Possessor groups. But we need the parentheses in order to apply the final asterisks (in lines 3, 4, 9 and 10) to the full match that they surround. What are they matching, exactly?\n\nThe main capturing groups for Possessed and Possessor want to match a common noun optionally preceded by one or more adjectives and one or more nouns. The match for a common noun is `[^\\s/]+ / nn [^\\s]*`. `[\\s/]` matches either a whitespace character or a slash; adding the `^` inverts the match to anything *but* a whitespace character or a slash; `+` requires one or more of them and `*`, zero or more. Therefore, this regex asks for a sequence of characters that are neither a whitespace character or a slash, (e.g. *idea* or *student*), followed by a slash and then *nn*, followed by an optional sequence of characters that are not whitespace characters, in case the part-of-speech tag ends with an `s` (for plurar) or  `-tl`. We use `jj` instead of `nn` when we ask for adjectives and we also reject `$` at the end of the Possessor slot, because we don't want an s-genitive to match.\n\nWithin each non-capturing group, therefore, we match either an adjective or a noun, but we still get a match if neither of them occurs. They are also followed by `\\s+` to capture the whitespace characters between the words.\n\nFinally, lines 7 and 9 match the core of the *of*-genitive construction, i.e. *of/in* and *the/at*, surrounded and separated by whitespace characters.\n\nIn other words, we are asking for:\n\n- a word boundary,\n\n- followed by *the/at* and whitespace,\n\n- optionally followed by adjectives, each followed by whitespace, and then at least one common noun --- this is the first capturing group, the Possessed,\n\n- then whitespace, followed by *of/in*, whitespace, *the/at* and whitespace,\n\n- optionally followed by adjectives, each followed by whitespace, and then at least one common noun without the genitive tag --- this is the second capturing group, the Possessor.\n\n<!-- TODO talk about limitations -->\n\n<!-- The solution is far from perfect. Think about the following -->\n<!-- examples, how they are dealt with now, and how we would want to deal -->\n<!-- with them ideally: -->\n\n<!--  - the/at center/nn of/in the/at entire/jj two-and-a-half-mile/jj -->\n<!--    length/nn |of/in the/at project/nn -->\n<!--  - the/at growth/nn of/in the/at child's/nn$ conscience/nn -->\n<!--  - the/at boxy/jj look/nn of/in the/at '20's/nns and/cc '40's/nns -->\n<!--  - the/at confidence/nn of/in the/at Democratic/jj-tl rank/nn -->\n<!--    and/cc file/nn -->\n<!--  - the/at election/nn of/in the/at man/nn who/wps defeated/vbd him/ppo -->\n<!--  - the/at day-to-day/jj course/nn of/in the/at closest/jjt -->\n<!--    Presidential/jj-tl election/nn in/in American/jj history/nn -->\n\n<!-- Likewise, the solutions we will use for the other queries have their -->\n<!-- limitations. A more thorough case study would imply a step of -->\n<!-- manual correction of the results (perhaps in combination with -->\n<!-- further refinements of the queries). -->\n\n### Code\n\nWe build the concordance with `conc()`, which takes a corpus or filenames, e.g. `brown_fnames`, and a regular expression to match, e.g. `pattern`. We can then explore the concordance with `print_kwic()`, `explore()` or `View()`. This really is advisable, in order to inspect how good the regex pattern is and see if you might want to refine it to capture patterns that were missed, or to exclude patterns that should be discarded.[With practice, you'll find the balance between refining the automatic process and performing manual cleaning. In some cases, it's quicker to fix the automatic procedure; in other cases, manual adjustments are easier and more reliable.]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncd <- brown_fnames %>%\n  conc(pattern)\nprint_kwic(cd, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nidx                      left|        match        |right                   \n  1 ... suit/nn to/to test/vb|the/at va...at act/nn|,/, and/cc then/rb th...\n  2 ...n/cd dollars/nns at/in|the/at en...j year/nn|next/ap Aug./np 31/cd...\n  3 ...e/ber teaching/vbg ./.|The/at re...rement/nn|would/md be/be in/in ...\n  4 ...ill/md retire/vb at/in|the/at cl...n term/nn|./. Dr./nn-tl Clark/n...\n  5 ... ``/`` Actually/rb ,/,|the/at ab...rocess/nn|may/md have/hv consti...\n  6 .../at 23d/od ward/nn ./.|The/at ca...udges/nns|in/in the/at 58th/od ...\n  7 ...O/nn line/nn ./. On/in|the/at ne... sheet/nn|must/md be/be set/vbn...\n  8 ...the/at alliance/nn ,/,|the/at us...ion/nn-tl|for/in-tl Economic/jj...\n  9 ...ns as/ql well/rb as/cs|the/at ma...errent/nn|./. This/dt increase/...\n 10 ...ey/ppss count/vb on/in|the/at ai...tries/nns|attending/vbg the/at ...\n...\n```\n:::\n:::\n\n\nBecause `cd` is also a dataframe, of which `match` is a column, we can also inspect the elements in the `match` by extracting the corresponding columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(cd$match)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"the/at validity/nn of/in the/at act/nn \"                              \n[2] \"the/at end/nn of/in the/at current/jj fiscal/jj year/nn \"             \n[3] \"The/at remainder/nn of/in the/at 4-year/jj college/nn requirement/nn \"\n[4] \"the/at close/nn of/in the/at present/jj school/nn term/nn \"           \n[5] \"the/at abuse/nn of/in the/at process/nn \"                             \n[6] \"The/at case/nn of/in the/at judges/nns \"                              \n```\n:::\n:::\n\n\nOnce we have a decent concordance, we can add variables that are characteristic of it. All of these observations will have the value *of* in the `gen_type` variable and the value *common* in the `possessor_type` variable. In addition, we can extract the constituents of the Possessed and Possessor slots with `mclm::re_replace_first()`. The first argument is a text to match, e.g. the elements in the `match` column; the second is a regular expression to match in the text, e.g. `pattern`, and the third is a replacement string. `\"\\\\1\"` and `\"\\\\2\"` correspond to the contents of the first and second capturing group in `pattern`, respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncd <- mutate(cd,\n    gen_type = \"of\",\n    possessor_type = \"common\",\n    possessed = re_replace_first(match, pattern, \"\\\\1\"), \n    possessor = re_replace_first(match, pattern, \"\\\\2\") \n)\ncd %>% \n  as_tibble() %>% \n  select(match, possessed, possessor) %>% \n  head() %>% \n  kbl() %>% \n  kable_paper()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> match </th>\n   <th style=\"text-align:left;\"> possessed </th>\n   <th style=\"text-align:left;\"> possessor </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> the/at validity/nn of/in the/at act/nn </td>\n   <td style=\"text-align:left;\"> validity/nn </td>\n   <td style=\"text-align:left;\"> act/nn </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at end/nn of/in the/at current/jj fiscal/jj year/nn </td>\n   <td style=\"text-align:left;\"> end/nn </td>\n   <td style=\"text-align:left;\"> current/jj fiscal/jj year/nn </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> The/at remainder/nn of/in the/at 4-year/jj college/nn requirement/nn </td>\n   <td style=\"text-align:left;\"> remainder/nn </td>\n   <td style=\"text-align:left;\"> 4-year/jj college/nn requirement/nn </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at close/nn of/in the/at present/jj school/nn term/nn </td>\n   <td style=\"text-align:left;\"> close/nn </td>\n   <td style=\"text-align:left;\"> present/jj school/nn term/nn </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at abuse/nn of/in the/at process/nn </td>\n   <td style=\"text-align:left;\"> abuse/nn </td>\n   <td style=\"text-align:left;\"> process/nn </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> The/at case/nn of/in the/at judges/nns </td>\n   <td style=\"text-align:left;\"> case/nn </td>\n   <td style=\"text-align:left;\"> judges/nns </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Of-genitive with proper nouns\n\nThe second query also captures the *of*-genitive variant, but with proper nouns in the Possessor slot instead, e.g. *the rivers of Belgium*.\n\n### Regular expression\n\nThe regular expression is very similar to the one for the first query, with a few differences:\n\n- It does not ask or even accept an article after *of/in*.\n\n- The noun(s), requested in lines 10 and 11 are proper nouns instead of common nouns.\n\n- Between the optional adjective(s) and the noun(s) of the second capturing group, i.e. the Possessor slot, we also accept optional items with any part-of-speech as long as they also end in *-nt* (line 9).\n\n::: {.callout-warning}\n#### Rewriting variables\n\nNotice that we are rewriting the variable `pattern` with the regex for the second query, so, if you suddenly wanted to rerun the first query, you would need to change `pattern` again.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\npattern <- r\"--[(?xi)\n       \\b         the / at                 \\s+\n       ( (?:  [^\\s/]+ / jj         [^\\s]*  \\s+ )*\n         (?:  [^\\s/]+ / nn         [^\\s]*  \\s+ )*\n              [^\\s/]+ / nn         [^\\s]*\n         )                                 \\s+\n                   of / in                 \\s+\n       ( (?:  [^\\s/]+ / jj         [^\\s]*  \\s+ )*\n         (?:  [^\\s/]+ / [^\\s]+ -tl [^\\s$]* \\s+ )*\n         (?:  [^\\s/]+ / np         [^\\s$]* \\s+ )*\n              [^\\s/]+ / np         [^\\s$]* \n       )                                   \\s\n]--\"\n```\n:::\n\n\n### Code\n\nThe steps are the same as for the first query. We store the object in a different variable, `cd_new`, and we assign the value *proper* to `possessor_type` instead of *common*. Afterwards, we rewrite `cd` to be the combination of `cd` (the first query) and `cd_new` (the second query) using `merge_conc()`, an `{mclm}` wrapper for `bind_rows()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncd_new <- brown_fnames %>%\n  conc(pattern) %>%\n  mutate(\n    gen_type = \"of\",\n    possessor_type = \"proper\",\n    possessed = re_replace_first(match, pattern, \"\\\\1\"), \n    possessor = re_replace_first(match, pattern, \"\\\\2\")  \n  )\nprint_kwic(cd_new, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nidx                      left|        match        |right                   \n  1 ...he/at state/nn with/in|the/at ex...ton/np-tl|County/nn-tl ,/, whic...\n  2 ...Thursday/nr despite/in|the/at ad... Texas/np|bankers/nns ./. Danie...\n  3 ...proved/vbd Thursday/nr|the/at bi...khouse/np|of/in Dallas/np autho...\n  4 .../cd session/nn upon/in|the/at re...ckland/np|./. State/nn and/cc f...\n  5 ...l avoided/vbn-hl In/in|the/at ca...rtugal/np|,/, which/wdt a/at fe...\n  6 ...lomat/nn described/vbd|the/at te...l Dean/np|Rusk's/np$ speeches/n...\n  7 .../jjr support/nn for/in|the/at in...n Cuba/np|by/in exile/nn groups...\n  8 .../cd factor/nn was/bedz|the/at st...bright/np|(/( D/np )/) of/in Ar...\n  9 ...ounced/vbd Thursday/nr|the/at ap...ackett/np|,/, a/at special/jj a...\n 10 ...cept/vb them/ppo at/in|the/at su...np Sr./np|./. The/at law/nn whi...\n...\n```\n:::\n\n```{.r .cell-code}\ncd <- merge_conc(cd, cd_new)\nnrow(cd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4157\n```\n:::\n:::\n\n\n## S-genitive with common nouns\n\nThe third query retrieves attestations of the *s*-genitive variant with common nouns in the Possessor slot, e.g. *the student's idea*.\n\n### Regular expression\n\nThe main regular expression symbols are the same used in the previous queries. The main differences with the first regular expression are twofold. First, we don't have word between the two capturing groups; instead, we only have whitespace, and the noun in line 5 must include *\\$* somewhere in its part-of-speech tag.\nSecond, the first capturing group now represents the Possessor, and the second capturing group, the possessed. This doesn't affect the writing of the regular expression itself, other than the requirement of *\\$* at the end of the first component and that it should *not* be present in the second component. However, it will affect the code below when extracting the Possessed and Possessor variables.\n\nAgain, here we overwrite the `pattern` variable with the new regular expression.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\npattern <- r\"--[(?xi)\n      \\b         the / at                  \\s+\n      (  (?: [^\\s/]+ / jj  [^\\s]*          \\s+ )*\n         (?: [^\\s/]+ / nn  [^\\s]*          \\s+ )*\n             [^\\s/]+ / nn  [^\\s]* [$] [^\\s]*\n       )                                   \\s+\n      (  (?: [^\\s/]+ / jj  [^\\s]*          \\s+ )*\n         (?: [^\\s/]+ / nn  [^\\s]*          \\s+ )*\n             [^\\s/]+ / nn  [^\\s$]*            \n       )                                   \\s \n]--\"\n```\n:::\n\n\n### Code\n\nNow that we have merged the first two queries into `cd`, we don't need `cd_new` anymore, so we can overwrite it with the output of the third query. Again, we call `conc()` with `brown_fnames` and the new `pattern` and assign the values that correspond to this concordance: *s* for `gen_type` and *common* for `possessor_type`, and the appropriate capturing groups of the pattern for `possessed` and `possessor`. Since the word order is inverted in relation to the *of*-genitive, now the first capturing group corresponds to the Possessor and the second one to the Possessed.\n\nFinally, we use `merge_conc()` to merge the output of the first two queries, `cd`, with the output of the third query, `cd_new`, overwriting `cd`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncd_new <- brown_fnames %>%\n  conc(pattern) %>%\n  mutate(\n    gen_type = \"s\",\n    possessor_type = \"common\",\n    possessed = re_replace_first(match, pattern, \"\\\\2\"), \n    possessor = re_replace_first(match, pattern, \"\\\\1\")  \n  )\nprint_kwic(cd_new, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nidx                      left|        match        |right                   \n  1 ...bd a/at swipe/nn at/in|the/at St...ndling/nn|of/in federal/jj fund...\n  2 ...and/cc in/in effect/nn|the/at co...wards/nns|from/in undue/jj cost...\n  3 ...petition/nn listed/vbd|the/at ma...pation/nn|as/cs ``/`` attorney/...\n  4 ...e/at petition/nn as/cs|the/at ma...torney/nn|./. Hartsfield/np has...\n  5 ...l/nn in/in 1923/cd ./.|The/at ma...j term/nn|of/in office/nn expir...\n  6 ...nn-tl to/to rescind/vb|the/at bo...action/nn|of/in Friday/nr in/in...\n  7 ...t gift/nn out/rp of/in|the/at ta...ckets/nns|to/in banks/nns ,/, i...\n  8 ... bill/nn extending/vbg|the/at St...hority/nn|to/to give/vb plannin...\n  9 ...en's/np$ attack/nn ./.|The/at bi...nders/nns|were/bed mostly/rb sm...\n 10 ...s/np ,/, Kan./np as/cs|the/at sc...sident/nn|./. Dr./nn-tl Clark/n...\n...\n```\n:::\n\n```{.r .cell-code}\ncd_new %>% \n  as_tibble() %>% \n  select(match, possessed, possessor) %>% \n  head() %>% \n  kbl() %>% \n  kable_paper()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> match </th>\n   <th style=\"text-align:left;\"> possessed </th>\n   <th style=\"text-align:left;\"> possessor </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> the/at State/nn-tl Welfare/nn-tl Department's/nn$-tl handling/nn </td>\n   <td style=\"text-align:left;\"> handling/nn </td>\n   <td style=\"text-align:left;\"> State/nn-tl Welfare/nn-tl Department's/nn$-tl </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at court's/nn$ wards/nns </td>\n   <td style=\"text-align:left;\"> wards/nns </td>\n   <td style=\"text-align:left;\"> court's/nn$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at mayor's/nn$ occupation/nn </td>\n   <td style=\"text-align:left;\"> occupation/nn </td>\n   <td style=\"text-align:left;\"> mayor's/nn$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at mayor's/nn$ attorney/nn </td>\n   <td style=\"text-align:left;\"> attorney/nn </td>\n   <td style=\"text-align:left;\"> mayor's/nn$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> The/at mayor's/nn$ present/jj term/nn </td>\n   <td style=\"text-align:left;\"> present/jj term/nn </td>\n   <td style=\"text-align:left;\"> mayor's/nn$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> the/at body's/nn$ action/nn </td>\n   <td style=\"text-align:left;\"> action/nn </td>\n   <td style=\"text-align:left;\"> body's/nn$ </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ncd <- merge_conc(cd, cd_new)\nnrow(cd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5207\n```\n:::\n:::\n\n\n## S-genitive with proper nouns\n\nThe fourth query captures the *s*-genitive variant with proper nouns in the Possessor slot, e.g. *Belgium's rivers*.\n\n### Regular expression\n\nAgain we overwrite `pattern` with the regular expression for the last query, which is very similar to the third query. The difference, like the difference between the second and the first, is that it asks of proper nouns instead of common nouns in the Possessor slot (lines 4 and 5; but also it excludes articles at the beginning) and that it allows for any item with *-tl* in its part-of-speech tag preceding the Possessor noun (line 3).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\npattern <- r\"--[(?xi)\n        \\b  ( (?: [^\\s/]+ / jj         [^\\s]*          \\s+ )*\n              (?: [^\\s/]+ / [^\\s]+ -tl [^\\s]*          \\s+ )*\n              (?: [^\\s/]+ / np         [^\\s$]*         \\s+ )*\n                  [^\\s/]+ / np         [^\\s]* [$] [^\\s]*        \n            )                                          \\s+\n            ( (?: [^\\s/]+ / jj         [^\\s]*          \\s+ )*\n              (?: [^\\s/]+ / nn         [^\\s]*          \\s+ )*\n                  [^\\s/]+ / nn         [^\\s$]*           \n            )                                          \\s\n]--\"\n```\n:::\n\n\n### Code\n\nAgain we overwrite the now useless `cd_new` with the output of the fourth query and assign the appropriate values for the common variables. The `possessor_type` is no *proper*, but the rest of the variables take the same values as in the previous query. At the end, we overwrite `cd` by merging the old `cd`, which contains the output of the first three queries, and `cd_new`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncd_new <- brown_fnames %>%\n  conc(pattern) %>%\n  mutate(\n    gen_type = \"s\",\n    possessor_type = \"proper\",\n    possessed = re_replace_first(match, pattern, \"\\\\2\"), \n    possessor = re_replace_first(match, pattern, \"\\\\1\")  \n  )\nprint_kwic(cd_new, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nidx                      left|        match        |right                   \n  1 ...investigation/nn of/in|Atlanta's...ection/nn|produced/vbd ``/`` no...\n  2 ... that/cs many/ap of/in|Georgia's...ration/nn|and/cc election/nn la...\n  3 ...mplementation/nn of/in|Georgia's...nn law/nn|was/bedz also/rb reco...\n  4 ...d/vbd ./. Regarding/in|Atlanta's...irport/nn|,/, the/at jury/nn re...\n  5 ...r to/to work/vb for/in|Lt./nn-tl...mpaign/nn|./. Caldwell's/np$ re...\n  6 ...'s/np$ campaign/nn ./.|Caldwell'...nation/nn|had/hvd been/ben expe...\n  7 ... that/cs none/pn of/in|Georgia's...ssmen/nns|specifically/rb asked...\n  8 ...tions/nns ./. Under/in|Formby's/np$ plan/nn |,/, an/at appointee/n...\n  9 ...ter/nn needs/nns of/in|Texas'/np...ities/nns|Thursday/nr ./. Rep./...\n 10 ... did/dod not/* sway/vb|Cotten's/...attack/nn|./. The/at bill's/nn$...\n...\n```\n:::\n\n```{.r .cell-code}\ncd_new %>% \n  as_tibble() %>% \n  select(match, possessed, possessor) %>% \n  head() %>% \n  kbl() %>% \n  kable_paper()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> match </th>\n   <th style=\"text-align:left;\"> possessed </th>\n   <th style=\"text-align:left;\"> possessor </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Atlanta's/np$ recent/jj primary/nn election/nn </td>\n   <td style=\"text-align:left;\"> recent/jj primary/nn election/nn </td>\n   <td style=\"text-align:left;\"> Atlanta's/np$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Georgia's/np$ registration/nn </td>\n   <td style=\"text-align:left;\"> registration/nn </td>\n   <td style=\"text-align:left;\"> Georgia's/np$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Georgia's/np$ automobile/nn title/nn law/nn </td>\n   <td style=\"text-align:left;\"> automobile/nn title/nn law/nn </td>\n   <td style=\"text-align:left;\"> Georgia's/np$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Atlanta's/np$ new/jj multi-million-dollar/jj airport/nn </td>\n   <td style=\"text-align:left;\"> new/jj multi-million-dollar/jj airport/nn </td>\n   <td style=\"text-align:left;\"> Atlanta's/np$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Lt./nn-tl Gov./nn-tl Garland/np Byrd's/np$ campaign/nn </td>\n   <td style=\"text-align:left;\"> campaign/nn </td>\n   <td style=\"text-align:left;\"> Lt./nn-tl Gov./nn-tl Garland/np Byrd's/np$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Caldwell's/np$ resignation/nn </td>\n   <td style=\"text-align:left;\"> resignation/nn </td>\n   <td style=\"text-align:left;\"> Caldwell's/np$ </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ncd <- merge_conc(cd, cd_new)\nnrow(cd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7344\n```\n:::\n:::\n\n\n# Automatic annotation\n\nWe now have a concordance `cd` with 7344 observations matching four different patterns. We can get a quick overview of the size of each subset with `xtabs()`. Here we can see that the most common pattern is the *of* genitive with a common noun in the Possessor slot, but also that within the *s* variant the proper noun is more common.\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\nxtabs(~ gen_type +\n        possessor_type,\n      data = cd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        possessor_type\ngen_type common proper\n      of   3151   1006\n      s    1050   2137\n```\n:::\n:::\n\n\n:::{.callout-tip}\n\nIt's a good idea to practice quick overview functions, such as `xtabs()` and `table()` from Base R, as well as `count()` and `summarize()` from `{tidyverse}`. Running sophisticated analysis should not push us away from simpler forms of exploration of the data.\n\n:::\n\nBefore saving our concordance, we can add some automatic annotation. The following `dplyr::mutate()` call adds or manipulates columns in different ways:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\ncd <- mutate(cd,\n  possessed = re_replace_all(possessed, \n                             r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\", \n                             \"\\\\1\") %>% \n              tolower(),\n  possessor = re_replace_all(possessor, \n                             r\"--[(?xi) ([^\\s/]+?) ('s)? / [^\\s]+ ]--\", \n                             \"\\\\1\") %>% \n              tolower(),\n  comp = re_retrieve_first(source, \".(.)..$\", requested_group = 1),\n  left_tagged = left,\n  left        = re_replace_all(left_tagged, \n                               r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\", \n                               \"\\\\1\"),\n  match_tagged = match,\n  match        = re_replace_all(match_tagged, \n                                r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\", \n                                \"\\\\1\"),\n  right_tagged = right,\n  right        = re_replace_all(right_tagged, \n                                r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\", \n                                \"\\\\1\"),\n  size_possessed = log(nchar(possessed)),\n  size_possessor = log(nchar(possessor)),\n  size_diff      = size_possessor - size_possessed\n)\n```\n:::\n\n\n- Lines 2-4 remove the part-of-speech tags from the text in the `possessed` column, overwriting. They do so by replacing all matches of the regular expression in line 3 as found in the text in line 2, i.e. the content of the `possessed` column, with the match of the first capturing group. The regular expression captures sequences of characters that are neither whitespace nor slashes, followed by a slash and then by another sequence of non whitespace characters, e.g. *the/at* and *example/nn*. The capturing group surrounds the first sequence before the slash, and therefore the result would replace *the/at example/nn* with *the example*.\n\n- Line 5 converts the new contents of `possessed` to lowercase, which is useful if you want to use the column as a random effect in regression analysis.\n\n- Lines 6-8 do the same as lines 2-4 but for the `possessor` column, and as such also exclude the optional *'s* sequence by leaving it out of the capturing group. Line 9 does the same as line 5, for the new contents of `possessor`.\n[In this example, `re_replace_all()` and `re_retrieve_first()` seem to be doing the same thing: they match a regular expression to a piece of text and extract the contents of the first captured group. The difference is that `re_replace_all()` will replace *all* matches in a piece of text with the contents of the replacement string --- if there are multiple matches, because there are multiple words, it will replace each group of `wordform/pos` with `wordform`. `re_retrieve_first()`, instead, will extract the first match of the pattern in the text, regardless of whether there are capturing groups; specifying `requested_group = 1` narrows down the return value to the match of the first capturing group in the match.]{.aside}\n\n- Line 9 creates a column `comp` that reads the column `source`, where the names of the files are stored, and extracts the third to last character by using `re_retrieve_first()` with the pattern `.(.)..$` and specifying that we want the first captured group. This character corresponds to the genre assignment of the file and could be used in modelling.\n\n- Lines 11-13, 15-17 and 19-21 do the same as lines 2-4 for the columns `left`, `match` and `right` respectively. However, since we might want to keep the original, tagged text as well, lines 10, 14 and 18 stored the original values of these columns in new columns, `left_tagged`, `match_tagged` and `right_tagged` respectively.\n\n- Lines 22 and 23 count the number of characters in each row of `possessed` and `possessor` with `nchar()` and then take their logarithm with `log()`. For example, for a word such as *example*, `nchar(\"example\")` returns 7, and `log(nchar(\"example\"))` returns 1.946; for *the example*, `nchar(\"the example\")` returns 11, and `log(nchar(\"the example\"))` returns 2.398. You can retrieve the original length by applying `exp()`: `exp(log(nchar(\"the example\"))` returns 11. Line 24 computes the difference between the logged size of the possessor and that of the possessed, giving us positive numbers when the possessor is longer and negative otherwise.\n\n:::{.callout-tip collapse=\"true\"}\n### EXTRA: Writing your own functions\n\nThe code above has some repetition: the `re_replace_all()` calls in lines 2, 6, 11, 15 and 19 all have the same structure. The first call and the three last calls only differ in the first argument (`possessed`, `left_tagged`, `match_tagged` or `right_tagged`), whereas the second call has a different first argument and a different pattern.\n\nIt is often useful ---as long as it doesn't hamper interpretation--- to avoid repetition in coding. First, the more you type, the more chances you have of mistyping something. Second, if you want to \"always do the same thing\" but then you change your mind on what that thing should be, e.g. you want to refine the regex, it would be beter to only have to change it once, and not every time you do it.\n\nThis can be achieved with variables and functions. For example, instead of typing or copy-pasting the regular expressions multiple times, you could write the following variable and then just call `pattern` instead of the regex in lines 3, 12, 16 and 20 We have done this above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\"\n```\n:::\n\n\nBut, since the whole function call is pretty much the same, you could create your own function with one argument: the variable you want to change. After the code below, you could replace the full call from lines 2 to 4 with a simple `remove_tags(possessed)` in line 2, and the same, changing the name of the column, with the last three calls of `re_replace_all()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremove_tags <- function(column) {\n  re_replace_all(column,\n                 r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\", \n                 \"\\\\1\")\n}\n```\n:::\n\n\nHowever, this doesn't work with the second call of `re_replace_all()`, since it uses a different pattern. You could either keep it that way, i.e. not replacing it with `remove_tags()`, or add an optional argument for the regular expression. The default value could be the most common regular expression, and then when you call `remove_tags()` on `possessor()` you could provide the appropriate regex.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremove_tags <- function(\n    column,\n    regex = r\"--[(?xi) ([^\\s/]+) / [^\\s]+ ]--\"\n    ) {\n  re_replace_all(column,\n                 regex, \n                 \"\\\\1\")\n}\n```\n:::\n\n\nWith this definition, the code from above would look as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\ncd <- mutate(cd,\n  possessed = remove_tags(possessed) %>% tolower(),\n  possessor = remove_tags(possessor, \n                          r\"--[(?xi) ([^\\s/]+?) ('s)? / [^\\s]+ ]--\") %>% \n              tolower(),\n  comp = re_retrieve_first(source, \".(.)..$\", requested_group = 1),\n  left_tagged = left,\n  left        = remove_tags(left_tagged),\n  match_tagged = match,\n  match        = remove_tags(match_tagged),\n  right_tagged = right,\n  right        = remove_tags(right_tagged),\n  size_possessed = log(nchar(possessed)),\n  size_possessor = log(nchar(possessor)),\n  size_diff      = size_possessor - size_possessed\n)\n```\n:::\n\n\nIn fact, you could make the code even shorter by replacing these new lines 2, 8, 10 and 12 with a single call to across: `across(c(possessed, left, match, right), remove_tags)`. Remember to first create the `_tagged` columns, or you will lose the tagged versions of the text.\n\n:::\n\n## Citing examples in markdown\n\nWith this new version of the concordance, which you can explore with `print_kwic(cd)`, `View(cd)` or `explore(cd)`, you can also extract full examples. If you use R Markdown or Quarto to write a report, rather than copy-pasting an example to describe, you can join the new `left`, `match` and `right` columns and call a specific example to illustrate.\n\nIn the following code:\n\n- The calls to `unite()` create a column with the name of the first argument (`conc_line` or `id`) by joining the rest of the columns mentioned (`left`, `match` and `right`, or `source` and `id`). By default they are separated with an underscore, but the `sep` argument allows you to use a different term.\n\n- The call to `select()` extracts only the `id` and `conc_line` columns. Ã€fterwards, `deframe()` turns the two-column tibble into a named character vector: the values are the contexts and their names, the ids.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexamples <- cd %>% \n  as_tibble() %>% \n  mutate(source = gsub(paste0(corpus_folder, \"/\"), \"\", source)) %>% \n  unite(conc_line, left, match, right, sep = \" \") %>% \n  unite(id, source, id) %>% \n  select(id, conc_line) %>%\n  deframe()\n\nhead(examples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                                                                                                                                                                                                                                                         ca01_1 \n                         \"ns million worth of highway reconstruction bonds . The bond issue will go to the state courts for a friendly test suit to test  the validity of the act  , and then the sales will begin and contracts let for repair work on some of Georgia's most heavily traveled highways . A H\" \n                                                                                                                                                                                                                                                                                                         ca02_2 \n             \"servative '' his estimate that it would produce 17 million dollars to help erase an anticipated deficit of 63 million dollars at  the end of the current fiscal year  next Aug. 31 . He told the committee the measure would merely provide means of enforcing the escheat law which has been on\" \n                                                                                                                                                                                                                                                                                                         ca02_3 \n\"over also would require junior-senior high teachers to have at least 24 semester hours credit in the subject they are teaching .  The remainder of the 4-year college requirement  would be in general subjects . `` A person with a master's degree in physics , chemistry , math or English , yet who has n\" \n                                                                                                                                                                                                                                                                                                         ca02_4 \n                            \"/np Clark of Hays , Kan. as the school's new president . Dr. Clark will succeed Dr. J. R. McLemore , who will retire at  the close of the present school term  . Dr. Clark holds an earned Doctor of Education degree from the University of Oklahoma . He also received a Master\" \n                                                                                                                                                                                                                                                                                                         ca03_5 \n                                \"d jury room '' . He said this constituted a `` very serious misuse '' of the Criminal court processes . `` Actually ,  the abuse of the process  may have constituted a contempt of the Criminal court of Cook county , altho vindication of the authority of that court is n\" \n                                                                                                                                                                                                                                                                                                         ca03_6 \n                            \"at 21st and 28th precincts of the 29th ward , the 18th precinct of the 4th ward , and the 9th precinct of the 23d ward .  The case of the judges  in the 58th precinct of the 23d ward had been heard previously and taken under advisement by Karns . Two other cases also were/\" \n```\n:::\n\n```{.r .cell-code}\nexamples[[\"ca01_1\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ns million worth of highway reconstruction bonds . The bond issue will go to the state courts for a friendly test suit to test  the validity of the act  , and then the sales will begin and contracts let for repair work on some of Georgia's most heavily traveled highways . A H\"\n```\n:::\n:::\n\n\nThen you could write, in an empty line of your report, a numbered example with R inline code: ``(@label) `r examples[[\"ca01_1\"]]` ``. Then you can easily cite the example with `(@label)`, which produces (@label).\n\n(@label) ns million worth of highway reconstruction bonds . The bond issue will go to the state courts for a friendly test suit to test  the validity of the act  , and then the sales will begin and contracts let for repair work on some of Georgia's most heavily traveled highways . A H\n\nYou might also want to, first, modify the `match` column, for example to add underscores or asterisks around it so that markdown turns them into italics or boldface.\n\n## Save your progress and be free! {#save}\n\nWe are DONE. Congratulations! We can now store the output in a tab-separated file with `write_conc()`. Then you can open the file with any spreadsheet software for manual cleaning and/or annotation and then read it again from R with `mclm::read_conc(filename)`.[Spreadsheet programs may call this format a \"csv\", comma-separated values file. What matters is that it's a plain text file. A proper csv file will have commas to separate the different columns, or semicolons in some places where commas are used to indicate decimals. However, this is meant for numbers: texts, such as concordances, will inevitably have commas and probably also semicolons. Therefore, we use tabs to separate the columns instead.]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_conc(cd,\n           file.path(data_folder, \"genitive-alternation.tab\"))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}