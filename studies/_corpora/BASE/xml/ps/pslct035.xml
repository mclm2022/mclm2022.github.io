<?xml version="1.0"?>
<!DOCTYPE TEI.2 SYSTEM "base.dtd">
<TEI.2><teiHeader>	
<fileDesc>
<titleStmt>
<title>Artificial Life</title></titleStmt>
<publicationStmt><distributor>BASE and Oxford Text Archive</distributor>
<idno>pslct035</idno>	
<availability><p>The British Academic Spoken English (BASE) corpus was developed at the
Universities of Warwick and Reading, under the directorship of Hilary Nesi
(Centre for English Language Teacher Education, Warwick) and Paul Thompson
(Department of Applied Linguistics, Reading), with funding from BALEAP,
EURALEX, the British Academy and the Arts and Humanities Research Board. The
original recordings are held at the Universities of Warwick and Reading, and
at the Oxford Text Archive and may be consulted by bona fide researchers
upon written application to any of the holding bodies.
The BASE corpus is freely available to researchers who agree to the
following conditions:</p>
<p>1. The recordings and transcriptions should not be modified in any
way</p>
<p>2. The recordings and transcriptions should be used for research purposes
only; they should not be reproduced in teaching materials</p>
<p>3. The recordings and transcriptions should not be reproduced in full for
a wider audience/readership, although researchers are free to quote short
passages of text (up to 200 running words from any given speech event)</p>
<p>4. The corpus developers should be informed of all presentations or
publications arising from analysis of the corpus</p><p>
Researchers should acknowledge their use of the corpus using the following
form of words:
The recordings and transcriptions used in this study come from the British
Academic Spoken English (BASE) corpus, which was developed at the
Universities of Warwick and Reading under the directorship of Hilary Nesi
(Warwick) and Paul Thompson (Reading). Corpus development was assisted by
funding from the Universities of Warwick and Reading, BALEAP, EURALEX, the
British Academy and the Arts and Humanities Research Board. </p></availability>
</publicationStmt>
<sourceDesc>
<recordingStmt>
<recording dur="00:51:25" n="6782">
<date>30/11/1998</date><equipment><p>video</p></equipment>
<respStmt><name>BASE team</name>
</respStmt></recording></recordingStmt></sourceDesc></fileDesc>
<profileDesc>
<langUsage><language id="en">English</language>
</langUsage>
<particDesc>
<person id="nm0938" role="main speaker" n="n" sex="m"><p>nm0938, main speaker, non-student, male</p></person>
<person id="sm0939" role="participant" n="s" sex="m"><p>sm0939, participant, student, male</p></person>
<personGrp id="ss" role="audience" size="l"><p>ss, audience, large group </p></personGrp>
<personGrp id="sl" role="all" size="l"><p>sl, all, large group</p></personGrp>
<personGrp role="speakers" size="4"><p>number of speakers: 4</p></personGrp>
</particDesc>
<textClass>
<keywords>
<list>
<item n="speechevent">Lecture</item>
<item n="acaddept">Psychology</item>
<item n="acaddiv">ps</item>
<item n="partlevel">UG</item>
<item n="module">Introduction to Psychology</item>
</list></keywords>
</textClass> 
</profileDesc></teiHeader><text><body>
<u who="nm0938"><kinesic desc="overhead projector is on showing transparency" iterated="n"/> can i <pause dur="0.4"/> just back that up <pause dur="0.2"/> Cumberland Lodge is the most brilliant deal you could possibly imagine <pause dur="0.7"/> it's the # <pause dur="1.1"/> it's owned by the # <pause dur="0.2"/> the royal family it's actually owned by the Queen Mother i think and it's where the royal family keep <pause dur="0.4"/> a small portion of their fabulous # art collection <pause dur="0.7"/> # it's in the middle of Windsor Great Park which is # <pause dur="0.4"/> tremendous as a # a place to go walking <pause dur="0.5"/> and we've got a good <pause dur="0.5"/> # a good programme sort of shaping up <pause dur="0.6"/> we've got # <pause dur="1.0"/> # <pause dur="0.4"/> Professor # <pause dur="1.3"/> # Ray Ball from York University who talks about political <pause dur="0.4"/> # rhetoric <pause dur="0.4"/> about how different politicians # <pause dur="0.6"/> conceal their intentions and tell you lies all the time <pause dur="0.7"/> # <pause dur="0.3"/> we've got # somebody coming to talk about # cognitive rehabilitation <pause dur="0.6"/> # <pause dur="0.3"/> that is how how you help people to <pause dur="0.6"/> # <pause dur="1.1"/> get back on their feet after they've had brain damage and so on <pause dur="0.4"/> and there are lots of other lots of other events # <pause dur="0.2"/> that # <pause dur="0.3"/> that <pause dur="0.2"/> that we do at Cumberland Lodge <pause dur="0.2"/> and <pause dur="0.8"/> generally speaking <pause dur="0.2"/> and people have a great time <pause dur="0.4"/> and <pause dur="0.3"/> if if you are going 
there as a part of a <pause dur="0.5"/> it's it's the place is sort of hired out to companies and if if # <pause dur="0.2"/> if a company like I-C-I <pause dur="0.5"/> # <pause dur="0.5"/> send somebody to Cumberland Lodge they pay a thousand pounds per person per day <pause dur="1.1"/> and you get <pause dur="0.2"/> three days there for fifty quid <pause dur="0.4"/> # <pause dur="0.2"/> again courtesy of something called the Saint Catherine's Foundation <pause dur="0.4"/> which again is financed by the <pause dur="0.3"/> the royal family <pause dur="0.4"/> so i i strongly recommend it <pause dur="0.9"/> and # <pause dur="0.5"/> we we've got # <pause dur="0.2"/> places are limited but you know the more people apply <pause dur="0.3"/> the more places we can have <pause dur="2.5"/> okay now i'm <trunc>to</trunc> <pause dur="0.2"/> today <pause dur="0.2"/> # i'm going to be talking about <pause dur="0.3"/> artificial life <pause dur="0.9"/> and # <pause dur="2.6"/> # i'm afraid that the <pause dur="0.2"/> the sound system has packed up in here so i'm afraid once again i this this mike is for the # camera here it's it's not <pause dur="0.5"/> # <pause dur="0.8"/> # <pause dur="0.2"/> the the audio <pause dur="0.3"/> system in here <pause dur="0.6"/> # so if if people at the back can't hear me <pause dur="0.4"/> # <pause dur="0.2"/> just just shout out during the lecture and i'll i'll raise the <pause dur="0.4"/> # <pause dur="2.5"/> i'll raise the volume a bit <pause dur="11.9"/><kinesic desc="turns on overhead projector showing transparency" iterated="n"/> i'm also going to 
# slow show some slides and videos so i'm afraid there's going to be a bit of # <pause dur="3.1"/><event desc="moves screen" iterated="n"/> # <pause dur="3.0"/> fiddling about with # with with technical stuff <pause dur="0.4"/> 'cause i haven't had time to # <pause dur="1.1"/> put it all together because the lecture theatre was full <pause dur="3.4"/> okay <pause dur="3.3"/> for a long time <pause dur="0.6"/> # <pause dur="3.3"/> artificial intelligence <pause dur="0.7"/> has <pause dur="0.9"/> # <pause dur="2.7"/> dominated <pause dur="1.6"/> # <pause dur="2.4"/> the the study of <pause dur="0.9"/> of <trunc>intelli</trunc> of of <pause dur="0.2"/> of the human mind <pause dur="0.4"/> this is what i was telling you <pause dur="0.8"/> in the first lecture that i gave <pause dur="1.0"/> that <pause dur="1.2"/> we have <pause dur="0.3"/> as it were a a <pause dur="1.7"/> a new discipline <pause dur="0.4"/> called cognitive science <pause dur="0.9"/> which brings together <pause dur="0.3"/> all sorts of different disciplines neuroscience anthropology linguistics psychology philosophy and artificial intelligence and you'll notice that <pause dur="0.7"/> there's there's quite a strong link between artificial intelligence and psychology <pause dur="1.7"/> and artificial intelligence <pause dur="0.6"/> has <pause dur="0.2"/> as it were had a good run for its money about <pause dur="0.5"/> # thirty years' worth really <pause dur="0.7"/> and <pause dur="0.2"/> # <pause dur="2.7"/> you'll find remarks like this being made <pause dur="1.2"/> <reading>artificial intelligence A-I is the single most important 
<trunc>d</trunc> <pause dur="0.2"/> development in the history of psychology</reading> <pause dur="0.6"/> # <reading>the computer is the last metaphor for the mind <pause dur="0.5"/> # <pause dur="0.8"/> we shall ever need</reading> <pause dur="0.4"/> and <reading>at last we know what the mind is <pause dur="0.5"/> it's a symbol it's a physical symbol system</reading> <pause dur="1.1"/><event desc="takes off transparency" iterated="n"/> now this is this is the central idea in artificial intelligence and and and what does that <pause dur="0.8"/> what does that idea <pause dur="0.2"/> really mean <pause dur="9.8"/> well what it what it means actually refers to that <pause dur="1.0"/> picture i put up a while ago <pause dur="1.1"/><kinesic desc="puts on transparency" iterated="n"/> at the beginning <pause dur="2.2"/> you remember <pause dur="0.5"/> that <pause dur="1.6"/> in the <pause dur="0.6"/> fifteenth century <pause dur="0.7"/> the Christian mystic John Flood <pause dur="1.7"/> he <pause dur="0.4"/> asked us to imagine <pause dur="0.3"/> that the mind somehow reflected the external world <pause dur="1.9"/> and the external world was <pause dur="1.1"/> ordered <pause dur="0.2"/> structured <pause dur="0.6"/> by <pause dur="0.3"/> the Creator <pause dur="0.8"/> and that somehow the <pause dur="0.4"/> the microcosm what was in the head <pause dur="0.5"/> reflected the macrocosm <pause dur="0.4"/> the the universe outside it <pause dur="0.5"/> the senses were <pause dur="0.3"/> related to the different planets and <pause dur="0.4"/> and a whole <pause dur="0.5"/> integrated <pause dur="0.6"/> view <pause dur="0.2"/> of <pause dur="0.3"/> the mind and how it fitted into the universe <pause dur="0.8"/> but following the <pause dur="1.8"/> industrial <pause dur="0.2"/> scientific <pause dur="0.4"/> and intellectual 
revolutions following the <pause dur="0.2"/> enlightenment <pause dur="0.2"/><vocal desc="clears throat" iterated="n"/><pause dur="0.2"/> the past three-hundred years <pause dur="1.1"/> of European history <pause dur="0.3"/> instead we tend to think of ourselves now as <pause dur="0.5"/> # <pause dur="0.2"/> machines who think <pause dur="0.5"/> the brain is some sort of information processing device <pause dur="0.7"/><event desc="looks through transparencies" iterated="y" dur="20"/> and artificial intelligence is the most <pause dur="0.6"/> # <pause dur="1.7"/> if you like <pause dur="0.2"/> # <pause dur="3.4"/> extended <pause dur="0.2"/> attempt <pause dur="1.0"/> to <pause dur="6.3"/> sorry i'm i'm <pause dur="0.3"/> i'm faffing about here because i've realized i've forgotten to bring <pause dur="0.7"/><vocal desc="clears throat" iterated="n"/><pause dur="2.5"/> some <pause dur="0.4"/> # <pause dur="2.0"/> some overhead transparencies but i i can do without them <pause dur="0.3"/><vocal desc="clears throat" iterated="n"/><pause dur="2.7"/> the idea <pause dur="1.0"/> behind <pause dur="0.2"/> the <pause dur="0.6"/> the mind as computer <pause dur="0.2"/> actually can be traced back <pause dur="0.5"/> to <pause dur="0.2"/> the <pause dur="0.3"/> the philosopher <pause dur="0.3"/> Hobbes <pause dur="0.2"/> Thomas Hobbes <pause dur="0.3"/> whose great <pause dur="0.7"/> # political treatise <pause dur="0.4"/> the Leviathan <pause dur="0.6"/> actually began <pause dur="0.9"/> with <pause dur="0.6"/> # <pause dur="0.3"/> a long <pause dur="0.7"/> discourse about the nature of the mind <pause dur="0.6"/> his idea <pause dur="0.4"/> of <pause dur="0.4"/> the <pause dur="0.3"/> ideal <pause dur="0.6"/> political <pause dur="0.8"/> system <pause dur="0.8"/> was based on the idea that first we must understand what human beings are really like <pause dur="0.5"/> and how <pause dur="0.2"/> their minds work <pause dur="0.2"/> in order <pause dur="0.3"/> to <pause dur="1.8"/> devise a system within which they can live together safely <pause dur="1.8"/> and without going into his political theory i just draw your 
attention to <pause dur="0.4"/><kinesic desc="indicates point on transparency" iterated="n"/>  these <pause dur="0.4"/> # remarks in effect <pause dur="0.8"/> # <pause dur="0.3"/> by ratiocination <pause dur="0.2"/> thinking <pause dur="0.6"/> i mean computation and that is Hobbes speaking in whenever it is <pause dur="0.3"/> about the sixteen-fifties <pause dur="3.0"/> that was the <pause dur="0.2"/> the centre of that diagram by Robert Flood ratio <pause dur="0.6"/> ratiocination rationality <pause dur="0.4"/> a Cartesian idea <pause dur="0.3"/> which says that the essence of the human mind <pause dur="0.3"/> is the ability <pause dur="0.4"/><kinesic desc="changes transparency" iterated="y" dur="9"/> to manipulate clear and distinct ideas <pause dur="0.6"/> and we have <pause dur="0.6"/> a <pause dur="0.2"/> a machine <pause dur="0.4"/> nowadays <pause dur="0.9"/> which does just that that's exactly what the computer does <pause dur="0.3"/> notice ratio <pause dur="0.2"/> right in the middle there <pause dur="2.3"/> and so <pause dur="0.5"/> the project of artificial intelligence <pause dur="1.5"/> # and these are the slides i'm afraid i've forgotten to bring with me but <pause dur="0.3"/> G-P-S stands for General <pause dur="0.2"/> Problem Solver <pause dur="0.7"/> is a classic example <pause dur="0.4"/> of a program <pause dur="0.5"/> which <pause dur="1.0"/> behaves intelligently solves <pause dur="0.2"/> problems <pause dur="0.4"/> and generally speaking <pause dur="0.7"/> # <pause dur="0.4"/> can be <pause dur="0.4"/> applied to a large variety of different situations <pause dur="0.7"/> # <pause dur="1.4"/> on the <trunc>ba</trunc> on the simple basis that <pause dur="0.7"/> it makes a representation <pause dur="0.3"/> of the world <pause dur="0.6"/> in terms of <pause dur="0.2"/> statements in a simple language <pause dur="1.9"/> and these statements can 
be manipulated <pause dur="0.8"/> to produce <pause dur="0.5"/> different representations <pause dur="0.3"/> of <pause dur="0.3"/> of the world as it might be <pause dur="1.6"/> and these are then checked against whether <pause dur="0.3"/> this representation of the world as it might be is getting you towards your goal <pause dur="0.5"/> you give the program <pause dur="0.3"/> a statement of the world as it is <pause dur="0.5"/> a statement of what you want <pause dur="0.6"/> and you let the program work out <pause dur="0.2"/> how to get from where you are <pause dur="0.3"/> to where you want to be <pause dur="1.5"/> so the classic example here might be something like a chessboard <pause dur="1.4"/> you tell the machine <pause dur="0.3"/> this is the way the chessboard is <pause dur="0.7"/> and you give it a <pause dur="0.8"/> # a general abstract description of what you want which is a position <pause dur="0.3"/> where <pause dur="0.3"/> you control the game <pause dur="0.2"/> if it's chess <pause dur="0.2"/> where <pause dur="0.3"/> the opponent's king <pause dur="0.4"/> is <pause dur="0.4"/> in check <pause dur="0.2"/> and can't move <pause dur="0.2"/> out of check <pause dur="1.4"/> and you win <pause dur="0.5"/> that's a statement an abstract statement of the goal you want to get to <pause dur="0.5"/> and <pause dur="0.3"/> the general problem solver <pause dur="1.0"/> would <pause dur="0.4"/> get from where it is <pause dur="0.3"/> to where you want it to be <pause dur="0.2"/> through a process of recognizing subgoals <pause dur="0.2"/> making moves and generally transforming the world until you get 
what you want <pause dur="1.5"/> now this is artificial intelligence <pause dur="1.1"/> it can be applied in all sorts of and and has been applied in all sorts of different <pause dur="0.2"/> # areas <pause dur="1.0"/> to solve problems <pause dur="0.4"/> to give medical diagnosis to # <pause dur="0.2"/> generally speaking <pause dur="0.2"/> do what human beings do when they're acting intelligently <pause dur="0.9"/> and there have been some tremendous successes <pause dur="1.7"/> but for one reason or another <pause dur="1.5"/> that <pause dur="0.2"/> project <pause dur="0.2"/> has run into trouble <pause dur="1.7"/> what we have discovered and that's the point i was making with those sentences remember # <pause dur="0.2"/> time flies like an arrow <pause dur="0.8"/> the point i was making with that example <pause dur="0.3"/> in the first lecture is that <pause dur="0.3"/> when you get <pause dur="0.2"/> into real <pause dur="0.7"/> human intelligence <pause dur="0.9"/> you find that <pause dur="0.2"/> even the simplest things like parsing a sentence <pause dur="0.3"/> requires <pause dur="0.8"/> a huge depth of knowledge <pause dur="1.5"/> and if you're going to approach <pause dur="0.8"/> intelligence on the basis of manipulating symbolic structures which represent that knowledge <pause dur="0.3"/> the machine has to get <pause dur="0.4"/> enormous <pause dur="0.2"/> huge <pause dur="0.7"/> now some people are still working on that basis they think they are going to produce <pause dur="0.6"/> # <pause dur="0.3"/> real intelligence <pause dur="0.5"/> 
and Allen Newell <pause dur="0.2"/> in fact <pause dur="0.2"/> <trunc>o</trunc> on that # <pause dur="0.4"/> that slide there <pause dur="7.6"/><kinesic desc="puts on transparency" iterated="n"/> this fellow <pause dur="0.7"/> Allen Newell <pause dur="0.8"/> # <pause dur="0.6"/> he died recently but just before he died he he wrote a book called <pause dur="0.3"/> # <pause dur="0.5"/> A Unified Theory of Cognition <pause dur="0.7"/> and he and his <pause dur="1.4"/> fellow <pause dur="0.2"/> research workers <pause dur="0.4"/> are still working on the idea that if you produce a machine <pause dur="0.5"/> with some <pause dur="0.4"/> symbolic manipulation capacity <pause dur="0.3"/> and a huge memory full of symbolic structures which represent everything it knows about the world <pause dur="0.2"/> it will <pause dur="0.3"/> like a <trunc>k</trunc> like a nuclear pile <pause dur="0.3"/> you keep on throwing in knowledge and eventually it sort of goes critical <pause dur="0.2"/> and begins to glow <pause dur="0.2"/> and begins to be intelligent <pause dur="3.8"/><event desc="takes off transparency" iterated="n"/> now other people for different reasons <pause dur="0.3"/> say <pause dur="0.2"/> this is bound to fail <pause dur="0.6"/> we simply can't do it <pause dur="1.2"/> it isn't going to be <pause dur="0.3"/> that easy <pause dur="1.4"/> and <pause dur="0.9"/> a different # <pause dur="0.7"/> two different approaches have well <pause dur="0.2"/> a number of different approaches have arisen <pause dur="0.4"/> i want to <trunc>wa</trunc> talk about one very <pause dur="0.4"/> quickly <pause dur="0.7"/> and that's connectionism <pause dur="0.3"/> and then i want to get on to the <pause dur="0.3"/> last but the the the focus 
of this <pause dur="0.6"/> week's lecture which is <pause dur="0.3"/> # artificial life and i have a <pause dur="0.2"/> a video to show <pause dur="0.4"/> of <pause dur="1.0"/> # well <pause dur="0.4"/> very nearly the latest a a a humanoid <pause dur="0.8"/> # robot <pause dur="0.3"/><vocal desc="clears throat" iterated="n"/><pause dur="1.2"/> connectionism <pause dur="0.3"/> is <pause dur="0.2"/> # a simple <pause dur="0.2"/> but radical idea <pause dur="0.6"/> which is that <pause dur="0.2"/> instead of <pause dur="0.7"/> trying to make artificial intelligence <pause dur="0.2"/> by programming it <pause dur="0.6"/><kinesic desc="puts on transparency" iterated="n"/> instead <pause dur="0.4"/> we can <pause dur="0.7"/> in effect <pause dur="2.9"/> we can grow it <pause dur="2.6"/> connectionism <pause dur="0.2"/> is sometimes called <pause dur="0.8"/> parallel distributed processing <pause dur="0.2"/> P-D-P <pause dur="0.5"/> and sometimes it's called neural networks <pause dur="0.6"/> what these networks are like <pause dur="0.6"/> is <pause dur="0.8"/> # a series of units <pause dur="0.3"/> some of which <pause dur="5.2"/> are <pause dur="0.4"/> connected <pause dur="1.0"/> to <pause dur="0.2"/> the outside world so these units <pause dur="0.3"/> which are <pause dur="0.3"/> could be each one could be a little computer or it could be some <pause dur="0.7"/> # bundle of electronics or it could be some <pause dur="0.3"/> simulation <pause dur="0.5"/> of # <pause dur="0.2"/> electronics <pause dur="0.3"/> are connected to something like a camera <pause dur="0.3"/> or a <pause dur="0.6"/> # a microphone <pause dur="0.5"/> or in some way they are driven by the outside world <pause dur="1.2"/> in between <pause dur="0.4"/> there are a number of <pause dur="0.2"/> units which are connected to the inputs <pause dur="0.2"/> and to each other <pause dur="0.5"/> and they're also connected to output units <pause dur="0.9"/> and in effect <pause dur="0.5"/> you allow these 
units to adjust <pause dur="1.1"/> their <trunc>con</trunc> their connectivity with each other <pause dur="1.4"/> you nobody intervenes in this network <pause dur="0.2"/> the network learns <pause dur="1.9"/> and <pause dur="1.9"/> what what <trunc>connectio</trunc> <trunc>ha</trunc> these connectionist systems work <pause dur="0.3"/> by having <pause dur="0.4"/> networks of units with <pause dur="0.4"/> dense connections between them <pause dur="0.3"/> which can be excitatory or inhibitory <pause dur="0.5"/> or they can be <pause dur="0.2"/> simply <pause dur="0.4"/> # there or not there <pause dur="2.0"/> as the network <pause dur="0.9"/> as it were <pause dur="0.2"/> experiences inputs <pause dur="0.8"/> from here <kinesic desc="indicates point on screen" iterated="n"/> <pause dur="0.3"/><vocal desc="clears throat" iterated="n"/><pause dur="1.2"/> it also <pause dur="1.8"/> # <pause dur="0.2"/> is <pause dur="0.2"/> trained <pause dur="0.3"/> by inputs which are not shown on this diagram <pause dur="0.3"/> which in effect <pause dur="0.6"/> # <pause dur="1.2"/> tell the units <pause dur="0.9"/> what <pause dur="0.3"/> is right and what is wrong <pause dur="1.2"/> and <pause dur="0.7"/> after a while <pause dur="0.5"/> the network <pause dur="0.4"/> has learned <pause dur="0.3"/> it it learns to for example <pause dur="0.6"/> # <pause dur="0.7"/> identify <pause dur="0.8"/> faces <pause dur="0.5"/> there's there's # # <pause dur="0.2"/> Professor Igor Alexander at # Imperial College <pause dur="0.6"/> # has <pause dur="0.3"/> built a number of networks which for example <pause dur="0.9"/> # i could # i could take somebody's face <pause dur="0.5"/><kinesic desc="indicates member of audience" iterated="n"/> # <pause dur="1.0"/> take a number of <pause dur="0.2"/> # different photographs of it <pause dur="0.2"/> train the network up <pause dur="0.4"/> to <trunc>ne</trunc> <pause dur="0.2"/> to recognize <pause dur="0.2"/> that face <pause dur="0.5"/> it would then <pause dur="0.2"/> recognize that face <pause dur="0.5"/> in <pause dur="0.4"/> # <pause dur="1.0"/> profile for example where it hadn't seen it before or it might 
recognize it upside down or you can put on a false beard and glasses and it still recognizes the face <pause dur="0.9"/> and you can put the <pause dur="0.4"/> network which is trained to recognize this face into a camera <pause dur="0.4"/> swing it around the crowd and <shift feature="pitch" new="high"/>ding <shift feature="pitch" new="normal"/><pause dur="0.4"/><kinesic desc="indicates member of audience" iterated="n"/> it picks you out <pause dur="1.1"/> and if you wonder what those <pause dur="0.2"/> cameras which you now see increasingly hanging below the <pause dur="0.5"/> # <pause dur="0.9"/> bridges of <pause dur="0.2"/><vocal desc="clears throat" iterated="n"/><pause dur="0.6"/> motorway <pause dur="0.5"/> <trunc>u</trunc> <trunc>u</trunc> under motorways are doing <pause dur="0.5"/><vocal desc="clears throat" iterated="n"/><pause dur="0.4"/> what they're doing is using neural networks <pause dur="0.2"/> to recognize <pause dur="0.2"/> number plates <pause dur="1.5"/> and these things are extremely effective <pause dur="0.3"/> they can recognize fingerprints they can recognize voices they can recognize handwriting <pause dur="1.1"/> # <pause dur="1.1"/> and this is something that <pause dur="0.2"/> that good old-fashioned artificial intelligence that's what GOFAI stands for <pause dur="0.2"/> good old-fashioned artificial intelligence <pause dur="0.2"/> which recognize things on the basis of making a description of your face <pause dur="0.3"/> in some sort of <pause dur="0.5"/> # <pause dur="0.2"/> symbolic language <pause dur="0.2"/> and then trying to recognize it <pause dur="0.3"/> it turned out to be extremely difficult <pause dur="0.7"/> but <pause dur="0.2"/> training <pause dur="0.2"/> artificial neural networks to recognize things <pause dur="0.2"/> 
turns out to be much easier and much more powerful </u><pause dur="1.8"/> <u who="sm0939" trans="pause"> does one camera search for one number plate <pause dur="0.2"/> or does it </u><pause dur="1.1"/> <u who="nm0938" trans="pause"> no <pause dur="0.3"/> you can </u><u who="sm0939" trans="latching"> well does one network search for one number plate <gap reason="inaudible" extent="1 sec"/> </u><u who="nm0938" trans="overlap"> no i mean once <pause dur="0.4"/> you know let let's let's # let's assume that you had a network for every face that you know <pause dur="1.3"/> you there's <trunc>n</trunc> there's no <pause dur="0.8"/> there's no problem in multiplying the networks <pause dur="0.7"/> so then you take one camera <pause dur="1.9"/> parallel <pause dur="0.3"/> the output of that camera to all these networks and the one that lights up that's the person you've got in front of you </u><u who="sm0939" trans="overlap"> do you have one network for each <pause dur="0.4"/> face <pause dur="0.4"/> or <pause dur="0.3"/> whatever you don't have networks which can recognize a number <unclear>of different things</unclear> </u> <u who="nm0938" trans="latching"> well in fact a number of networks are <pause dur="0.3"/> capable <pause dur="0.4"/> of <pause dur="0.3"/> for example one of the networks that # <pause dur="1.5"/> # <pause dur="0.9"/> <trunc>ic</trunc> # <pause dur="0.3"/> Alexander has trained <pause dur="0.5"/> # <pause dur="0.3"/> can distinguish between men and women <pause dur="1.4"/> so there's one network <pause dur="0.2"/> you show it a whole load of women <pause dur="0.5"/> and you say that's a woman <pause dur="0.3"/> that's a woman <pause dur="0.3"/> that's a woman <pause dur="0.8"/> and then you show them a whole load of <trunc>m</trunc> men 
that's a man that's a man that's a man <pause dur="0.3"/> then you show them <pause dur="0.5"/> # a gender specific <pause dur="0.5"/> person <pause dur="0.5"/> # who they haven't seen before and they say that's a woman <pause dur="1.0"/> and it's right <pause dur="1.2"/> so networks are extremely flexible <pause dur="5.9"/> let's <trunc>t</trunc> let's take this on in the the seminars i mean <pause dur="0.5"/> <trunc>al</trunc> all i'm putting in front of you here is the idea <pause dur="0.3"/> that <pause dur="0.3"/> instead of programming intelligence <pause dur="0.2"/> we can grow it <pause dur="1.9"/> instead of <pause dur="0.7"/> somehow understanding intelligence in a formal <pause dur="0.3"/> Cartesian way writing down the <pause dur="0.3"/> the the <pause dur="0.3"/> the procedures that underlie our ability to play chess or to # have a conversation <pause dur="0.6"/> we are <pause dur="1.2"/> getting to the point where <pause dur="0.3"/> we're we're actually <pause dur="0.6"/> simulating <pause dur="0.6"/> the <pause dur="2.0"/> the the <pause dur="0.2"/> a <trunc>b</trunc> a biologically plausible model of what the brain is doing <pause dur="2.1"/> and notice there's <trunc>s</trunc> there's some really quite interesting philosophical <pause dur="0.3"/> conundrums here because <pause dur="0.2"/> say <pause dur="0.3"/> you get some artificial network <pause dur="0.2"/> which does something <pause dur="0.2"/> really quite interesting like recognize things <pause dur="0.3"/> and if someone comes up to you and says <pause dur="0.3"/> how does the network do it <pause dur="0.5"/> you 
actually can't say <pause dur="1.2"/> all you can say is well it's trained to do it <pause dur="0.8"/> and if someone says <pause dur="0.2"/> can you point to where the knowledge <pause dur="1.2"/> is in this network that allows us to recognize that face or that face <pause dur="0.3"/> you you can't you can just say well there's a whole mass of connections in there <pause dur="0.5"/> # <pause dur="0.3"/> and they do the job <pause dur="1.6"/> # i mean here's <pause dur="0.2"/> here's a <pause dur="0.4"/><kinesic desc="changes transparency" iterated="y" dur="3"/> # <pause dur="1.5"/> an example of <pause dur="1.5"/> # the idea that <pause dur="0.2"/> you <trunc>c</trunc> you can have networks to recognize letters <pause dur="0.5"/> and then these <pause dur="0.3"/> letters <pause dur="0.4"/> as it were are connected in the excitatory and inhibitory ways <pause dur="0.3"/> to a whole set of word recognition nodes in the network <pause dur="0.6"/> and <pause dur="0.3"/> simulating <pause dur="0.3"/> what human beings do <pause dur="0.3"/> in experiments in recognizing words and letters <pause dur="0.3"/> # can be done using networks really quite effectively <pause dur="2.2"/><event desc="takes off transparency" iterated="n"/> so <pause dur="0.7"/> i'm putting in front of you here the idea that we're moving from <pause dur="0.7"/> # <pause dur="0.8"/> understanding intelligence by <pause dur="1.6"/> <reading>programming it <pause dur="0.5"/> symbolically <pause dur="0.5"/> towards understanding intelligence in a more biologically plausible way</reading> <pause dur="1.0"/> and in connectionism <pause dur="1.3"/> the <pause dur="1.1"/> the <pause dur="0.2"/> the knowledge <pause dur="0.3"/> in a 
connectionist system is distributed there's no particular place where it is <pause dur="0.5"/> it runs in parallel <pause dur="0.3"/> and it doesn't depend upon symbols <pause dur="0.5"/> and in many people have said <pause dur="0.3"/> actually when you look at it that's the way the brain works <pause dur="0.7"/> when you open up the brain you don't see <pause dur="0.4"/> the sort of <pause dur="0.2"/> serial processor central processor structure that you <pause dur="0.2"/> find inside a normal computer <pause dur="0.3"/> instead you see a dense <pause dur="0.4"/> web <pause dur="0.7"/> which you can't understand simply by looking at it <pause dur="1.1"/> and good old-fashioned artificial intelligence <pause dur="0.2"/> is very much <pause dur="0.2"/> localized that is to say if you lose a bit of an old computer's memory <pause dur="0.3"/> you've lost that memory completely <pause dur="0.6"/> if you lose a bit of a connectionist network <pause dur="0.2"/> you haven't lost anything but the whole thing <pause dur="0.9"/> has # lost a little bit <pause dur="0.9"/> # good old-fashioned <pause dur="0.2"/> # artificial intelligence is definitely serial it's very fast but <pause dur="0.3"/> it's just one thing after another very quickly in a central processor <pause dur="0.3"/> and it depends essentially on <pause dur="0.3"/> symbolic <pause dur="0.3"/> representations of the 
environment <pause dur="0.3"/> and we strongly suspect <pause dur="0.3"/> that many <pause dur="0.4"/> good <pause dur="0.8"/> perfectly good cognitive beings like animals don't make <pause dur="0.6"/> symbolic representations of their environments at all <pause dur="0.5"/> but their nervous systems <pause dur="0.2"/> are tuned up to be able to act effectively <pause dur="1.1"/> this is a quotation from <pause dur="0.3"/> one of the people who <pause dur="0.4"/> # invented P-D-P they say <reading>connectionist systems don't contain knowledge just connections</reading> <pause dur="0.7"/> and # another quotation a similar one is that <pause dur="0.3"/> <reading>connectionist systems <pause dur="0.6"/> don't have any rules <pause dur="0.3"/> inside them <pause dur="0.2"/> they just behave as if they did</reading> <pause dur="5.6"/><kinesic desc="changes transparency" iterated="y" dur="10"/> however <pause dur="4.8"/> compared <pause dur="2.0"/> to connectionism <pause dur="0.4"/> artificial life is a much more fundamental break <pause dur="0.7"/> with artificial intelligence and i'd like to spend the rest of the lecture talking about that <pause dur="0.9"/> now <pause dur="0.2"/> what i mean by artificial life is anticipated a bit by connectionism <pause dur="0.6"/> for example <pause dur="0.4"/> some people have tried to build <pause dur="0.3"/> small <pause dur="0.2"/> walking <pause dur="0.2"/> robots <pause dur="0.8"/> and <pause dur="0.2"/> on the old idea what you did was <pause dur="0.3"/> you wrote a program <pause dur="0.3"/> which <pause dur="0.2"/> had instructions in it like lift the left leg <pause dur="0.2"/> 
move it forward <pause dur="0.2"/> drop it again <pause dur="0.3"/> and when you're stable <pause dur="0.2"/> do the same with the right leg <pause dur="0.2"/> and so on <pause dur="0.6"/> there's some sort of program <pause dur="0.3"/> inside the machine and you could point to different bits of the program <pause dur="0.3"/> and say <pause dur="0.3"/> that's what moves the leg like this and that's what moves the leg like that <pause dur="0.9"/> instead <pause dur="1.0"/> people have <pause dur="0.4"/> begun to build machines which <pause dur="0.3"/> have legs <pause dur="0.9"/> they have ways of moving those legs but they have no program <pause dur="0.7"/> instead <pause dur="0.4"/> they have <pause dur="0.4"/> a <pause dur="0.8"/> # <pause dur="2.3"/> a <pause dur="0.2"/> a dense <pause dur="0.6"/> set of <pause dur="0.2"/> connections inside them <pause dur="0.4"/> which <pause dur="0.8"/> gradually learn <pause dur="0.8"/> to control <pause dur="0.3"/> the organism <pause dur="0.4"/> let me give you # a brief illustration of this <pause dur="10.5"/><kinesic desc="puts on transparency" iterated="n"/> # <trunc>ne</trunc> never mind the text for the moment <pause dur="0.6"/> there's there's # <pause dur="0.3"/> a fish called a lionfish <pause dur="0.5"/> which # <pause dur="0.7"/> when it emerges from the egg <pause dur="0.3"/> it's simply got no idea <pause dur="0.8"/> it swims up <pause dur="0.2"/> down any which way it looks <pause dur="0.7"/> if they're very small and they look as if they're simply <pause dur="0.4"/> # <pause dur="0.5"/> mess in the water just floating about <pause dur="0.3"/><vocal desc="clears throat" iterated="n"/><pause dur="0.7"/> but after # some hours <pause dur="0.9"/> you see that their <pause dur="1.9"/> movements become less random <pause dur="0.9"/> and <pause dur="0.4"/> in 
effect <pause dur="0.9"/> what the <pause dur="0.5"/> what the <pause dur="0.4"/> the fish is doing <pause dur="0.7"/> is <pause dur="0.5"/> flapping its control surfaces at random <pause dur="0.7"/> and finding out the results <pause dur="0.2"/> of doing that <pause dur="0.6"/> and then gradually becoming less random <pause dur="0.6"/> to the point where it can swim straight and level <pause dur="0.4"/> now it has to have a balance organ to do that <pause dur="0.5"/> but <pause dur="0.4"/> # <pause dur="0.3"/> that's what it's doing <pause dur="0.3"/><kinesic desc="changes transparency" iterated="y" dur="3"/> it's learning about its own body <pause dur="0.9"/> well <pause dur="0.5"/> without <pause dur="0.4"/> going into detail <pause dur="0.9"/> this is the control structure of # <pause dur="0.3"/> an aquatic robot <pause dur="0.2"/> which does the same thing <pause dur="0.7"/> you toss it in the water it thrashes about <pause dur="0.5"/> you come back next morning and it's swimming around straight and level <pause dur="0.4"/> nobody has programmed it to do that it's learned how to do it <pause dur="0.9"/> this is artificial life <pause dur="4.0"/> <event desc="takes off transparency" iterated="n"/> now i'll i'll expand that <pause dur="0.2"/> with some examples <pause dur="4.0"/> in effect <pause dur="0.3"/> the program for artificial life <pause dur="0.3"/> is <pause dur="0.3"/> captured in these <pause dur="0.8"/> two quotations here <pause dur="1.9"/> <reading>the project is to capture the logical form of life <pause dur="0.3"/> in artefacts</reading> <pause dur="0.3"/> now logical form <pause dur="0.4"/> might mean things as <pause dur="0.7"/> # <pause dur="0.2"/> straightforward as let's say <pause dur="0.5"/><vocal desc="clears throat" iterated="n"/><pause dur="3.5"/><kinesic desc="puts on transparency" iterated="n"/> the growth 
patterns of plants <pause dur="0.6"/> now these these are plants which <pause dur="0.4"/> are <pause dur="1.4"/> generated on a computer screen <pause dur="0.5"/> but the manner in which they're generated we're now discovering <vocal desc="clears throat" iterated="n"/><pause dur="0.4"/> can be described by very simple rules <pause dur="1.3"/> what you see as the complex structure of an organism <pause dur="0.6"/> actually may be <pause dur="0.6"/> the <pause dur="0.4"/> product <pause dur="0.2"/> of rather simple <pause dur="0.2"/> growth rules <pause dur="0.5"/> and recent developments in mathematics particularly to do with fractals and chaos <pause dur="0.5"/> # <pause dur="0.2"/> are <pause dur="0.3"/> helping us to understand <pause dur="0.4"/> that <pause dur="0.2"/> what we might think of <pause dur="0.2"/> as being <pause dur="0.5"/> the <pause dur="0.3"/> the result of a complex genetic program actually might be the result of rather simpler <pause dur="0.3"/> growth <pause dur="0.3"/> patterns <pause dur="0.8"/> and <pause dur="0.2"/> here you have <pause dur="0.2"/> # plants which <pause dur="0.8"/> fundamentally the same formula with a few <pause dur="0.5"/> parameter changes produces different organisms and you can even <pause dur="0.3"/> account for the direction of the wind <pause dur="0.8"/> now these things are just structures inside computers but they could be actually <pause dur="0.2"/> built as well <pause dur="4.5"/><kinesic desc="changes transparency" iterated="y" dur="8"/> likewise <pause dur="3.5"/> here we have <pause dur="0.3"/> # <pause dur="0.2"/> real structures built by <pause dur="0.4"/> social insects wasps and bees <pause dur="0.7"/> and <pause dur="1.2"/> programming <pause dur="3.3"/> 
virtual insects as it were and allowing them <pause dur="0.3"/> to <pause dur="0.3"/> interact with each other <pause dur="0.8"/> produces structures which are beginning to capture <pause dur="0.4"/> the the sorts of patterns <pause dur="0.2"/> that <pause dur="0.3"/> we <pause dur="0.2"/> we see in nature <pause dur="0.6"/> these again are virtual patterns inside a machine but once again <pause dur="0.3"/><event desc="takes off transparency" iterated="n"/> they could be built <pause dur="0.3"/> quite easily <pause dur="2.2"/> what we're doing is we're <pause dur="0.2"/> we're moving towards capturing the logical form of life <pause dur="0.3"/> in artefacts <pause dur="0.5"/> and <pause dur="0.6"/> well i'll come on to this # at the end of the lecture but <pause dur="1.3"/> not only the life that we know about <pause dur="0.7"/> but <pause dur="0.2"/> the life that might be <pause dur="0.2"/> that is to say <pause dur="0.5"/> we may be <pause dur="0.2"/> on the brink of creating <pause dur="0.2"/> life forms <pause dur="0.4"/> which <pause dur="0.6"/> in a sense go beyond <pause dur="0.4"/> the D-N-A based life forms that we know and love <pause dur="0.3"/> and <pause dur="0.2"/> which we are ourselves <pause dur="2.4"/> so <pause dur="0.2"/> # i'm actually on to this <pause dur="0.5"/> this point here <pause dur="0.8"/><kinesic desc="indicates point on transparency" iterated="n"/> the examples of artificial life discovering the laws of growth and form that's what plants are about <pause dur="0.4"/> genetic algorithms and comfuter computer viruses <pause dur="0.5"/> these i mean you know about computer viruses <pause dur="0.3"/> these are information structures which reproduce themselves in the 
computer <pause dur="0.2"/> domain <pause dur="0.8"/> and <pause dur="1.7"/> # <pause dur="0.6"/> Thomas Ray <pause dur="0.4"/> has actually produced what he calls the Tierra Project <pause dur="0.3"/> which are <pause dur="0.4"/> <trunc>th</trunc> these are not viruses these are actually <pause dur="0.5"/> computational organisms that live on the Internet <pause dur="0.8"/> and they <pause dur="0.7"/> they transmit themselves and reproduce themselves in different computers wherever they can get <pause dur="0.6"/> and <pause dur="0.2"/> he sort of <pause dur="0.4"/> generated them and let them loose and now they are <pause dur="0.2"/> they're out there <pause dur="0.2"/> reproducing <pause dur="0.8"/> # with slight variations evolving <pause dur="0.2"/> some of them die some of them find it easier to survive if they mutate slightly <pause dur="0.8"/> # <pause dur="0.6"/> what are these things well <pause dur="0.2"/> they're they're <pause dur="0.3"/> they're digital organisms <pause dur="0.6"/> # it's been found that they tend to follow <pause dur="0.3"/> the shadow <pause dur="0.3"/> of <pause dur="0.3"/> they they they tend to hover <pause dur="0.2"/> the the the the <pause dur="0.5"/> the Internet covers the globe <pause dur="0.8"/> and they tend to be found <pause dur="0.3"/> in the dark part <pause dur="0.9"/> now why is that <pause dur="0.4"/> it's because then people go to sleep <pause dur="0.2"/> and the computers have got more room <pause dur="0.2"/> to host these organisms <pause dur="0.5"/> so they've actually developed <pause dur="0.6"/> organic patterns <pause dur="2.8"/> robots that learned to control their 
bodies that was that was the # the fish <pause dur="0.4"/> and once you <pause dur="0.2"/> # <pause dur="0.3"/> begin to <pause dur="0.6"/> # <pause dur="0.3"/> play with these sorts of things <pause dur="0.5"/> you can actually model <pause dur="0.5"/> individual fish <pause dur="0.4"/><kinesic desc="puts on transparency" iterated="n"/> like that <pause dur="0.2"/> real ones <pause dur="0.8"/> # <pause dur="0.7"/> and inside <pause dur="0.6"/> there's <pause dur="0.3"/> some sort of # <pause dur="0.3"/> set of <pause dur="0.4"/> program structures <pause dur="0.5"/> # <pause dur="0.3"/> <trunc>a</trunc> <pause dur="0.4"/> a <pause dur="0.3"/> very useful thing intention generators i <pause dur="0.3"/> you know i wish i had one every time you're at a loss you can just turn to your intention generator and have something new to do <pause dur="0.5"/> well <pause dur="1.5"/><kinesic desc="changes transparency" iterated="y" dur="9"/> these these things # actually are not so <pause dur="0.5"/> # extraordinary as they might sound <pause dur="0.5"/> # <pause dur="2.4"/> here's an intention generator <pause dur="0.8"/> # <pause dur="1.3"/> are are you # <pause dur="0.5"/><vocal desc="sniff" iterated="n"/><pause dur="0.7"/> are you on your own <pause dur="0.9"/> # <pause dur="2.2"/> sorry are you inside the pack <pause dur="0.7"/> is really what that statement is saying <pause dur="0.6"/> well no if you're not <pause dur="0.4"/> # <pause dur="0.8"/> find somebody and get close to them <pause dur="0.3"/> if you are <pause dur="0.4"/> stay roughly speaking near the centre of gravity of the whole <pause dur="0.7"/> pack you're in <pause dur="0.3"/> so if you if we produce a thousand virtual fish with these little intention generators inside them <pause dur="0.7"/> what they do is <pause dur="0.2"/> they flock <pause dur="1.2"/> they shoal <pause dur="0.4"/> they <pause dur="0.3"/><event desc="takes off transparency" iterated="n"/> they behave in an absolutely natural way <pause dur="0.9"/> which is if you if you <pause dur="0.2"/> 
frighten them they they scatter and then regroup again <pause dur="0.4"/> now nobody programmed them to do that <pause dur="0.6"/> all you did was put those little instructions inside each one <pause dur="0.7"/> and they <pause dur="0.2"/> they <pause dur="0.2"/> produce <pause dur="0.4"/> the the <pause dur="0.3"/> resultant structure <pause dur="0.5"/> # <pause dur="0.2"/> emerges <pause dur="6.3"/><vocal desc="sniff" iterated="n"/><pause dur="1.1"/> so the point i'm making there <pause dur="0.4"/> is that you can get what might appear to be complex behaviour from simple rules <pause dur="0.5"/> flocks <pause dur="1.0"/> of birds <pause dur="0.2"/> swarms of bees <pause dur="0.2"/> shoals of fishes <pause dur="0.4"/> seem to behave <pause dur="0.3"/> in an intelligent collective way <pause dur="0.4"/> well <pause dur="0.5"/> that <pause dur="0.8"/> collective intelligence emerges from very simple <pause dur="0.9"/> intelligence in each member of the flock <pause dur="0.5"/> or swarm or herd or whatever <pause dur="1.5"/> this is what the A-I project is about <pause dur="0.3"/> capturing <pause dur="0.3"/> the <pause dur="0.3"/> logical form <pause dur="0.4"/> of <pause dur="0.2"/> life in artefacts <pause dur="5.0"/> now <pause dur="0.3"/> what i want to <pause dur="0.6"/> # <pause dur="1.0"/> finish up with <pause dur="1.0"/> # <pause dur="0.7"/> is the <pause dur="1.0"/> the most # radical <pause dur="0.4"/> attempt <pause dur="0.4"/> to <pause dur="0.2"/> produce artificial life <pause dur="0.4"/> namely <pause dur="1.3"/> to produce a humanoid <pause dur="0.7"/> robot <pause dur="0.3"/><vocal desc="clears throat" iterated="n"/><pause dur="0.6"/> and this this is the the work of of Rodney Brooks <pause dur="0.5"/> who # at a at a conference a while back <pause dur="0.2"/> was asked generally <pause dur="0.4"/> what <pause dur="0.4"/> how he would describe his own work because sometimes he calls himself a psychologist <pause dur="0.3"/> sometimes he calls himself <pause dur="0.2"/> an engineer <pause dur="0.6"/> what he's doing <pause dur="0.5"/> is building <pause dur="0.6"/> a humanoid robot which i'll 
show you on a video in a minute <pause dur="1.7"/> and # somebody asked him well <pause dur="0.2"/> what sort of a thing are you what are you what are you doing are you an engineer are you a psychologist are you a philosopher what are you doing <pause dur="0.4"/> and he said well i'm a bit of everything <pause dur="0.4"/> and if you want me to describe my work i'd i'd put it like this <pause dur="0.7"/> <reading>i'm making a hope <pause dur="0.2"/> i'm making a <pause dur="0.2"/> home <pause dur="0.3"/> for the mind <pause dur="0.5"/> and hoping that the mind will come</reading> <pause dur="4.4"/> what he does is he builds <pause dur="1.1"/> he calls it behaviour based robotics he builds <pause dur="0.5"/> complete <pause dur="0.2"/> creatures <pause dur="0.8"/> and he <pause dur="1.5"/> described his <pause dur="0.2"/> # <pause dur="1.4"/> work a little bit like this <pause dur="9.2"/><kinesic desc="puts on transparency" iterated="n"/> <reading>a project to capitalize on computation to understand human cognition <pause dur="1.1"/> we will build an integrated physical system including vision sound input output <pause dur="0.5"/> manipulation <pause dur="0.7"/> # <pause dur="0.7"/> the resulting system will learn to think <pause dur="0.4"/> by building on its bodily experiences</reading> <pause dur="1.4"/> this is the Cog Project <pause dur="0.5"/><event desc="takes off transparency" iterated="n"/> it's it's come to be known as the Cog project <pause dur="0.4"/> and what i'd like to do now is to show you it <pause dur="0.8"/> now i don't know whether 
this is # <pause dur="0.6"/> how well this is going to work <pause dur="0.2"/> but let's have a go <pause dur="0.3"/><vocal desc="sniff" iterated="n"/><pause dur="12.0"/><event desc="prepares video" iterated="y" dur="40"/><event desc="turns off lights" iterated="n"/> okay i'll have to have the lights out to # <pause dur="0.3"/> to do this properly <pause dur="0.7"/> Cog <pause dur="0.3"/> is <pause dur="0.2"/> # <pause dur="0.4"/> a torso <pause dur="0.5"/> it starts at the hips <pause dur="0.3"/> ends at the head it's got a pair of arms <pause dur="1.1"/> un<pause dur="0.2"/>like <pause dur="0.2"/> most <pause dur="0.3"/> robotic research up to now it doesn't live in a laboratory <pause dur="0.5"/> it stands in the corridor at M-I-T <pause dur="0.4"/> and people who come by <pause dur="0.4"/> play with it <pause dur="1.3"/> and that's how it learns <pause dur="0.5"/> and what we've got here is # <pause dur="0.2"/> a video <pause dur="0.6"/> # this is Rod Brooks' work <pause dur="0.5"/> # <pause dur="0.6"/> a video <pause dur="0.3"/> which <pause dur="1.6"/> shows what Cog can do <kinesic desc="starts video" iterated="n"/><kinesic desc="video plays" iterated="y" dur="3:05"/> and i'll i'll it takes about five minutes <pause dur="0.2"/> it's got no sound i'll talk you through it <pause dur="1.3"/> so <pause dur="0.2"/> <reading>humanoid intelligence requires humanoid interactions with the world</reading> <pause dur="1.7"/> you'll see Cog in a second <pause dur="0.5"/> # <pause dur="0.7"/> it's that head <pause dur="1.6"/> there it is there's there's the head <pause dur="0.4"/> up there <pause dur="1.2"/> it's # <pause dur="1.3"/> it's not to clear in this # <pause dur="0.6"/> thing but this <trunc>i</trunc> this is Cog's <pause dur="0.3"/> arm <pause dur="0.7"/> and it's got # <pause dur="1.0"/> it's got something in it <pause dur="0.4"/> which <pause dur="0.2"/> # <pause dur="1.0"/> it's trying to hand 
to Rod Brooks but it's not doing too well at the moment <pause dur="1.1"/> there's its head <pause dur="1.0"/> and notice that <pause dur="0.9"/> as as it moves around the eyes <pause dur="0.2"/> and the head can move independently <pause dur="0.6"/> notice here <pause dur="1.5"/> the eyes <pause dur="0.2"/> follow objects around <pause dur="3.1"/> if you move it slowly <pause dur="0.2"/> the head follows it around <pause dur="1.4"/> if you move it quickly its eyes flick <pause dur="0.6"/> if you move it slowly <pause dur="0.2"/> it follows it with its head <pause dur="5.5"/> if you move its head <pause dur="0.5"/> its eyes stay still <pause dur="0.4"/> you can't <pause dur="0.3"/> you can't see this but <pause dur="3.0"/> its its eyes are looking in one direction <pause dur="1.0"/> it's got in effect <pause dur="0.4"/> # <pause dur="0.2"/> an optical reflex <pause dur="0.2"/> such as we have if we move your eyes quickly <pause dur="0.2"/> your head quickly sorry <pause dur="0.3"/> your eyes stay in the same place <pause dur="0.3"/> lots of animals have got it <pause dur="3.1"/> # this is Cog i think trying to find something <pause dur="0.3"/> it's looking for something <pause dur="5.0"/><vocal desc="laughter" iterated="y" n="ss" dur="2"/> here we are <pause dur="0.2"/> found it <pause dur="0.9"/> and if you make a move it picks up you <pause dur="1.7"/> i've heard people who've interacted it <pause dur="0.2"/> with it saying that it's the first time they've felt like <pause dur="0.4"/> they've they've been in the room with something <pause dur="0.9"/> it feels like <pause dur="0.4"/> you're with something to be with Cog <pause dur="0.5"/> now most industrial 
robots are very dangerous <pause dur="0.8"/> you have to put them <pause dur="0.6"/> behind <pause dur="0.3"/> 'cause they're so powerful you have to put them behind screens <pause dur="0.4"/> Cog is safe in the corridor <pause dur="0.6"/> it's actually quite cuddly <pause dur="4.7"/><vocal desc="laughter" iterated="y" n="ss" dur="3"/> # <pause dur="0.8"/> it doesn't mind being wrenched about a bit <pause dur="1.6"/> bit like a sort of friendly dog <pause dur="2.2"/><vocal desc="laughter" iterated="y" n="ss" dur="1"/> and if you wiggle it <pause dur="0.6"/> the actual mechanics of its body <pause dur="0.3"/> are sort of humanoid too <pause dur="4.9"/> and if given nothing to do it just sort of nuh-huh-nuh-huh-nuh-huh <vocal desc="laughter" iterated="y" n="ss" dur="3"/><pause dur="4.1"/> however <pause dur="0.2"/> if you leave it alone once it's been doing something it practises <pause dur="0.2"/> what it's been doing <pause dur="3.3"/> and you'll see in a second <pause dur="0.4"/> what it's practising <pause dur="1.5"/> but this is Cog <pause dur="0.3"/> having a think about what it's been doing just a moment ago <pause dur="1.9"/><vocal desc="laughter" iterated="y" n="ss" dur="1"/> oh <pause dur="0.2"/> well we can fast-forward this little bit <pause dur="0.9"/> this is this is a Cog's eye view of the world <pause dur="0.3"/><vocal desc="clears throat" iterated="n"/><pause dur="1.0"/> let me # <pause dur="4.2"/><event desc="stops video" iterated="n"/><event desc="fast-forwards video" iterated="y" dur="4"/><kinesic desc="starts video" iterated="n"/><kinesic desc="video plays" iterated="y" dur="54"/><event desc="moves screen" iterated="n"/> <shift feature="pitch" new="high"/>aagh <pause dur="1.4"/><vocal desc="laughter" iterated="y" n="ss" dur="3"/> no <shift feature="pitch" new="normal"/> stop <pause dur="1.8"/><vocal desc="laughter" iterated="y" n="ss" dur="2"/><vocal desc="laughter" iterated="y" dur="1"/><pause dur="1.8"/> right <pause dur="1.9"/><vocal desc="laughter" iterated="y" n="ss" dur="1"/> this <trunc>i</trunc> 
this is Cog <pause dur="0.2"/> reaching <pause dur="0.3"/> towards <pause dur="0.3"/> something it sees <pause dur="0.3"/> picks it up with its head <pause dur="1.0"/> and brings its hand out <pause dur="0.9"/> and actually this <trunc>i</trunc> this is a <pause dur="0.7"/> that's what it was <pause dur="0.2"/> that's what it was practising <pause dur="0.5"/> now here's somebody <pause dur="0.3"/> just <pause dur="0.5"/> playing around with Cog <pause dur="1.2"/> putting something in front of it and Cog <pause dur="0.6"/> sort of looks at the person looks at the object <pause dur="3.6"/> now my kids grew up pretty normal but that reminds me exactly of one of my daughters when she was about eighteen months old <pause dur="0.6"/><vocal desc="laughter" iterated="y" n="ss" dur="1"/> she'd sort of push things around do it and then <vocal desc="laughter" iterated="y" n="ss" dur="1"/><pause dur="0.3"/> wait for me to pick it up <pause dur="3.4"/> <vocal desc="laughter" iterated="y" n="ss" dur="1"/> but this is this is Cog <pause dur="1.5"/><event desc="stops video" iterated="n"/> learning to know its body <pause dur="0.9"/> here <pause dur="0.8"/> okay now this is <pause dur="1.0"/> what was that <pause dur="0.2"/> was that a <pause dur="2.4"/> was that psychology <pause dur="0.9"/> engineering <pause dur="0.4"/> # <pause dur="0.7"/> what was it <pause dur="0.5"/> well i i suggest <pause dur="0.2"/> it's <pause dur="0.5"/> # <pause dur="9.5"/><kinesic desc="changes transparency" iterated="y" dur="3"/> i i suggest it it's <pause dur="0.4"/> you might say <pause dur="0.2"/> cybernetic philosophy <pause dur="1.1"/> that is to say <pause dur="1.4"/> the Cog project can stand for a number of <pause dur="0.2"/> of projects around the world now which <pause dur="0.2"/> are <pause dur="0.5"/> attempts to create <pause dur="2.2"/> what in popular fiction would be called <pause dur="0.4"/> the <pause dur="0.2"/> the cyborg <pause dur="0.3"/> 
the cybernetic organism <pause dur="1.5"/> that is to say <pause dur="0.4"/> Cog <pause dur="0.4"/> begins to look <pause dur="0.4"/> like <pause dur="0.4"/> a a humanoid <pause dur="1.5"/> it has nothing <pause dur="0.2"/> inside it <pause dur="0.2"/> which has anything to do with artificial intelligence <pause dur="0.2"/> there are no representations <pause dur="0.7"/> no <pause dur="0.3"/> Cartesian <pause dur="0.4"/> ratio right in the middle <pause dur="0.6"/> it's just a <pause dur="0.2"/> a seething mass of lots of different connectionist systems <pause dur="1.1"/> different <pause dur="0.3"/> ways of getting <pause dur="2.2"/> different aspects of intelligence to interact <pause dur="0.2"/> with <pause dur="0.5"/> with <pause dur="0.9"/> each other <pause dur="0.9"/> and the the way that they interact is structured <pause dur="0.3"/> by Cog's interaction <pause dur="0.4"/> with <pause dur="0.2"/> the social world <pause dur="1.4"/> so what i'm putting in front of you is the proposition <pause dur="0.3"/> that what we are creating <pause dur="0.8"/> is <pause dur="1.5"/> artificial life <pause dur="0.4"/> which will in some sense share <pause dur="0.3"/> our <pause dur="0.4"/> social world <pause dur="1.3"/> and we will create <pause dur="0.3"/> artificial intelligence <pause dur="0.3"/> not by <pause dur="0.4"/> programming anything in explicit <pause dur="0.2"/> symbolic terms <pause dur="0.3"/> but by building <pause dur="0.9"/> machines which are broadly speaking organisms <pause dur="1.0"/> we are as it were <pause dur="1.3"/> making <pause dur="0.2"/> the artificial <pause dur="0.7"/> # <pause dur="0.6"/> natural <pause dur="0.9"/> by <pause dur="1.9"/> creating <pause dur="2.6"/> artefacts that can learn <pause dur="0.2"/> <trunc>a</trunc> <pause dur="0.2"/> to be part of our social world <pause dur="0.7"/> now <pause dur="2.1"/><kinesic desc="turns on overhead projector showing transparency" iterated="n"/> i want to finish this lecture by <pause dur="1.0"/> putting in front 
of you <pause dur="0.9"/> what may seem a rather odd proposition <pause dur="0.3"/> but it <pause dur="0.4"/> it is <pause dur="0.2"/> the proposition <pause dur="0.2"/> that actually <pause dur="0.2"/> we <pause dur="1.4"/> are such artefacts already <pause dur="2.8"/> this is Jonathan Kingdon who is a # <pause dur="0.5"/> a biologist who's very interested in evolution <pause dur="0.7"/> and what he claims is that human beings <pause dur="0.3"/> you know that <pause dur="0.2"/> our <pause dur="0.7"/> # <pause dur="0.2"/> genetic <pause dur="0.6"/> material <pause dur="0.5"/> overlaps with that <pause dur="0.2"/> of our <pause dur="0.7"/> close <pause dur="0.5"/> evolutionary relatives like <pause dur="0.9"/> the bonobo chimpanzees <pause dur="0.4"/> to something like ninety-nine per cent <pause dur="2.1"/> we are very <pause dur="0.4"/> similar genetically speaking to chimpanzees and yet we are completely different <pause dur="0.9"/> we have language we have culture and so on <pause dur="0.9"/> now i i should say incidentally that <pause dur="0.8"/> ninety-nine per cent <pause dur="0.3"/> might sound like a lot but we're we're thirty-<pause dur="0.3"/>three or so per cent <pause dur="0.3"/> identical with mushrooms <pause dur="1.3"/><vocal desc="laughter" iterated="y" n="ss" dur="2"/> so it it <pause dur="0.5"/> it isn't # quite the drama that it <pause dur="0.2"/> might first appear <pause dur="0.5"/> but what a lot of biologists are now saying and Jonathan Kingdon is one of them <pause dur="0.5"/> is that <pause dur="0.7"/> we don't need to look inside human beings for what makes us unique <pause dur="0.2"/> and different 
from animals <pause dur="0.4"/> instead <pause dur="0.3"/> we perhaps might look at what is outside <pause dur="0.7"/> and what <pause dur="0.3"/> we grow up <pause dur="0.4"/> within <pause dur="0.5"/> and Jonathan Kingdon puts it like this <pause dur="0.3"/> that human beings <pause dur="0.8"/> are in effect <pause dur="0.3"/> artefacts <pause dur="0.2"/> of their own artefacts <pause dur="0.5"/> now let me explain that <pause dur="1.7"/> if you think about <pause dur="0.6"/> # <pause dur="1.4"/> <trunc>i</trunc> what i what i'm playing with here is the idea that <pause dur="0.6"/> artificial life <pause dur="1.0"/> may be creating cyborgs but we may be cyborgs already <pause dur="3.3"/><event desc="takes off transparency" iterated="n"/> cultural evolution is much more important than biological evolution <pause dur="0.2"/> for us biological evolution stopped about two-hundred-thousand years ago <pause dur="1.3"/> it hasn't stopped but it's so slow <pause dur="0.2"/> compared to the evolutionary process that was unleashed <pause dur="0.4"/> once human beings could transmit information <pause dur="0.3"/> from generation to generation using culture <pause dur="1.3"/> that <pause dur="0.9"/> if you think about it wherever you look <pause dur="0.4"/> you find something <pause dur="0.2"/> that is made by human beings for human beings <pause dur="1.7"/> and <pause dur="0.6"/> babies grow up <pause dur="0.6"/> like the <pause dur="0.6"/> the lionfish there <pause dur="0.8"/> finding out what their body will do <pause dur="0.3"/> within an environment <pause dur="0.2"/> which is structured <pause dur="0.3"/> to bring out <pause dur="0.2"/> certain capacities from 
bodies <pause dur="2.2"/> so <pause dur="1.3"/> all the things that surround us <pause dur="0.2"/> from <pause dur="0.3"/> Stone Age stone tools <pause dur="0.2"/> up to <pause dur="0.2"/> digital watches <pause dur="0.8"/> are products of the human mind <pause dur="1.0"/> cultural <pause dur="0.3"/> artefacts <pause dur="0.2"/> are produced by minds <pause dur="0.4"/> but minds the human minds <pause dur="0.6"/> are produced <pause dur="0.3"/> by interacting <pause dur="0.2"/> with those <pause dur="0.3"/> cultural artefacts <pause dur="0.8"/> and so human the human condition <pause dur="0.5"/> is in fact intrinsically artificial <pause dur="2.8"/> and i'd invite you to think about this <pause dur="0.3"/> from the point of view of <pause dur="0.4"/> literature <pause dur="0.5"/> if we go back to <pause dur="0.5"/> the sixteenth century <pause dur="0.6"/> Cervantes' Don Quixote <pause dur="0.9"/> we find technology <pause dur="0.3"/> the windmills <pause dur="0.2"/> turning peacefully in the wind <pause dur="0.3"/> charged at <pause dur="0.4"/> by the sad knight <pause dur="0.3"/> on the basis that they are giants which he has to slay <pause dur="0.8"/> but the <pause dur="0.4"/> the technology <pause dur="0.5"/> is out there <pause dur="0.2"/> and human meanings are projected onto it <pause dur="2.5"/> if we go <pause dur="0.8"/> about three-<sic corr="hundred">hundyear</sic> <pause dur="0.2"/> years later to Charles Dickens in Hard Times <pause dur="0.2"/> we find that the machine <pause dur="0.3"/> is the central metaphor <pause dur="0.2"/> of Hard Times <pause dur="0.4"/> machines <pause dur="0.2"/> have now got their own meanings which they project onto human beings <pause dur="0.3"/> human beings have to serve the machines <pause dur="0.5"/> the 
machines are a a current theme within the <pause dur="0.4"/> a recurrent theme within the novel <pause dur="0.4"/> showing how people's lives are manipulated and warped <pause dur="0.3"/> by the powers of the machine and the needs <pause dur="0.3"/> of the machine <pause dur="1.5"/> and if we come up to date <pause dur="0.4"/> with contemporary cyberpunk fiction <pause dur="0.4"/> somebody like William Gibson <pause dur="0.5"/> in his novel Neuromancer or Mona Lisa Overdrive <pause dur="0.6"/> you'll find that now the image is of human existence <pause dur="0.3"/> passing <pause dur="0.2"/> from <pause dur="0.3"/> flesh <pause dur="0.4"/> into <pause dur="0.2"/> the <trunc>biolog</trunc> into the digital domain of the Internet <pause dur="1.4"/> this <pause dur="0.4"/> theme <pause dur="0.4"/> this image <pause dur="0.3"/> of the human condition somehow becoming technologized <pause dur="0.4"/> is a dominant theme <pause dur="0.3"/> in <pause dur="1.4"/> cyberpunk fiction <pause dur="0.8"/> as technology <pause dur="0.6"/> has <pause dur="0.8"/> developed so it has <pause dur="0.2"/> approached <pause dur="0.7"/> and been assimilated by <pause dur="0.2"/> the body <pause dur="1.2"/> let me just # <pause dur="0.3"/> give you a couple of <pause dur="3.2"/> examples <pause dur="0.8"/> if you think about what <pause dur="0.2"/> we <pause dur="0.4"/> # <pause dur="0.2"/> currently find around us in the the media <pause dur="2.4"/><kinesic desc="puts on transparency" iterated="n"/> we find <pause dur="0.3"/> an enormous <pause dur="0.4"/> enormously problematic control <pause dur="0.5"/> of <pause dur="0.6"/> let's say human reproduction <pause dur="0.4"/> we can now <pause dur="0.2"/> choose the genetic make-up of the next <pause dur="0.4"/> # generation <pause dur="0.7"/> # <pause dur="0.5"/> we are playing around with <pause dur="0.7"/> the idea that # <pause dur="4.3"/><kinesic desc="changes transparency" iterated="y" dur="3"/> 
i mean <kinesic desc="indicates point on transparency" iterated="n"/> <trunc>thi</trunc> this was taken from the Guardian a few weeks ago <pause dur="0.3"/> happened to be on the same page <pause dur="0.7"/> # <reading>spy camera matches <pause dur="0.3"/> faces to police files</reading> that's what neural networks are doing <pause dur="0.3"/> but brain implants now allow <pause dur="0.2"/> patients to work computers without touching them which is true you can put brains <pause dur="0.2"/> you can put <pause dur="0.3"/> # <pause dur="1.3"/> chips into the brain <pause dur="0.4"/> # in such a way that they're biologically incorporated into the workings of the nervous system <pause dur="0.2"/> and then they transmit <pause dur="0.4"/> # <pause dur="0.4"/> through a radio link <pause dur="0.3"/> to a computer and you for example can drive the cursor around the screen by thinking about it <pause dur="0.2"/> which is pretty handy if your body's paralysed which is what they're for <pause dur="0.8"/> this is # <pause dur="0.6"/> Kevin Warwick who's a <pause dur="0.3"/> professor of Computer Science at Reading <pause dur="0.4"/> # that little thing that he's holding up there <pause dur="0.3"/> is a silicon implant which # <pause dur="0.3"/> he put into his arm <pause dur="0.3"/> and whenever he approaches his department the computer in the department knows he's coming <pause dur="0.4"/> turns on his computer warms up his room <pause dur="0.3"/> opens the door for him <pause dur="0.4"/> # and generally gets the # <pause dur="0.8"/> intelligent department <pause dur="0.3"/> ready to # receive him <pause dur="0.7"/> and # as he puts it here <pause dur="0.5"/> 
<reading>cybernetics is all about humans and technology interacting <pause dur="0.4"/> for a professor of cybernetics to become a true cyborg <pause dur="0.3"/> part man part machine <pause dur="0.3"/> is rather appropriate</reading> <pause dur="2.0"/><kinesic desc="changes transparency" iterated="y" dur="2"/> so as <pause dur="0.2"/> we are <pause dur="1.1"/> technologizing <pause dur="0.2"/> the biological <trunc>con</trunc> condition <pause dur="0.3"/> so we are <pause dur="0.5"/> biologizing the <sic corr="technological">technologable</sic> <pause dur="0.2"/> <unclear><trunc>b</trunc></unclear> condition <pause dur="0.8"/> and as we assimilate <pause dur="0.2"/> technology so it <pause dur="0.2"/> it somehow disappears <pause dur="0.6"/> for example <pause dur="0.3"/> i find <pause dur="0.2"/> that people of my generation <pause dur="0.4"/> get bugged <pause dur="0.3"/> by <pause dur="0.4"/> computers # <pause dur="0.6"/> by telephone systems which are sort of complicated answering machines <pause dur="0.3"/> that # tell you <pause dur="0.2"/> if you want this press that if you want that press this and so on <pause dur="0.9"/> but i find that # <pause dur="1.5"/> younger people <pause dur="0.6"/> and particularly very young people <pause dur="0.3"/> are beginning not to care <pause dur="0.4"/> whether <pause dur="0.3"/> they talk on the phone <pause dur="0.4"/> with a human being <pause dur="0.4"/> or a machine <pause dur="0.6"/> they don't make that distinction <pause dur="1.4"/> and in many ways <pause dur="0.2"/> i <pause dur="0.2"/> i think <pause dur="0.3"/> this assimilation of <pause dur="0.3"/> technology is moving down <pause dur="0.4"/> the age scale <pause dur="0.3"/> at an increasing rate <pause dur="7.5"/><kinesic desc="changes transparency" iterated="y" dur="5"/> and <pause dur="2.5"/> the idea that <pause dur="0.3"/> somehow <pause dur="0.3"/> the machine <pause dur="1.0"/> will become <pause dur="0.9"/> human <pause dur="0.9"/> may sound like a 
contemporary <pause dur="0.4"/> cyberpunk fiction invention <pause dur="0.3"/> but in fact it was seen <pause dur="1.1"/> many many years ago particularly by Samuel Butler <pause dur="0.5"/> a Victorian <pause dur="0.6"/> # novelist and # <pause dur="0.7"/> literary figure <pause dur="0.4"/> friendly critic of the theory of evolution <pause dur="0.9"/> # <pause dur="0.6"/> and in his famous # satire on Victorian society Erewhon <pause dur="0.8"/> which <trunc>i</trunc> which stands for nowhere <pause dur="1.3"/> he <pause dur="0.3"/> he says there's there's no <pause dur="0.6"/> reason <pause dur="0.2"/> why machines couldn't develop consciousness <pause dur="1.4"/> in fact he he was the guy who said that a <trunc>po</trunc> even a potato has a sort of low form of cunning <pause dur="0.3"/> inside it <pause dur="1.1"/><vocal desc="laughter" iterated="y" n="ss" dur="1"/> and <pause dur="1.8"/> he <pause dur="1.2"/> he warned against this <pause dur="1.0"/> he said machines will become as it were a threat <pause dur="1.3"/> and if you look around now you'll find that machines are becoming intensely personalized <pause dur="0.3"/> people's <pause dur="0.6"/> personal <pause dur="0.7"/> computers are really personal <pause dur="0.3"/> that is to say <pause dur="0.3"/> they have their own <pause dur="0.4"/> # voice recognition routines which recognizes your voice but not somebody else <pause dur="0.3"/> it corrects your spelling mistakes but not somebody else it has your diaries but not somebody else <pause dur="0.9"/> and very soon <pause dur="0.7"/> well now <pause dur="0.3"/> people <pause dur="0.3"/> commit 
themselves so strongly to partnership with machines <pause dur="0.3"/> in which <pause dur="0.2"/> most of the artificial intelligence research is dumped <pause dur="0.3"/> that's that's where <pause dur="0.2"/> most of the M-I-T research used to be funded by the military <pause dur="0.9"/> but it's not any longer it's funded by Microsoft <pause dur="0.5"/> who want to make machines people <pause dur="1.4"/> and so cyborgs <pause dur="0.2"/> don't have to be <pause dur="0.2"/> as it were <pause dur="0.2"/> built in laboratories like Cog <pause dur="0.5"/> they will <pause dur="0.2"/> they will appear <pause dur="0.3"/> by humans integrating their <pause dur="0.2"/> everyday lives <pause dur="0.2"/> with machines which <pause dur="0.2"/> know them as people <pause dur="0.4"/> and you can see that happening <pause dur="0.3"/> in the shape of electronic pets <pause dur="0.5"/> what are those little things called </u><pause dur="0.5"/> <u who="ss" trans="pause"> Tamagotchi </u><u who="nm0938" trans="latching"> <trunc>tam</trunc> Tamagotchi things <pause dur="0.3"/> well imagine <pause dur="0.6"/> you know imagine what they're going to be like in fifty years <pause dur="0.2"/> when they actually run around you know they'll be furry they'll have big eyes <kinesic desc="demonstrates big eyes with hands" iterated="n"/> like this <vocal desc="laughter" iterated="y" n="ss" dur="1"/><pause dur="0.5"/> and they'll know your voice and not somebody else's <pause dur="0.4"/> you'll be able to teach them tricks which nobody else will be able to make 
them do <pause dur="0.6"/> and for a lonely kid <pause dur="0.2"/> they will be <pause dur="0.6"/> extremely powerful companions <pause dur="0.6"/> and they will not be machines any longer <pause dur="0.3"/> they will be part of the social world <pause dur="1.5"/> in fact <pause dur="0.3"/> somebody <pause dur="0.2"/> called Moravec who was one of Brooks' # <pause dur="2.3"/> research partners has written a book called Mind Children <pause dur="0.2"/> in which he claims <pause dur="0.3"/> that it won't take very long <pause dur="0.3"/> before <pause dur="0.3"/> artefacts computer artefacts <pause dur="0.2"/> in a sense <pause dur="0.6"/> continue the life of individuals after they've died <pause dur="0.8"/> computers will make us immortal <pause dur="2.3"/> so i <pause dur="0.2"/> i will finish with this <pause dur="0.4"/> this idea <pause dur="0.2"/> that artificial life in its many forms <pause dur="0.2"/> is actually <pause dur="0.8"/> the making of artefacts which are organic <pause dur="0.5"/> and it's no accident that it's happening at a time <pause dur="0.3"/> when organic things <pause dur="0.2"/> are being made into mechanisms <pause dur="1.4"/> but all these things <pause dur="0.2"/> require some sort of <pause dur="0.3"/> control <pause dur="0.9"/> and <pause dur="0.2"/> human beings have the ability to control themselves <pause dur="0.4"/> we call it <pause dur="0.2"/> paying attention <pause dur="0.3"/> and we'll deal with that next week
</u></body>
</text></TEI.2>