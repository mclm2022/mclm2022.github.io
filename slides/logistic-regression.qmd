---
title: "Logistic regression analysis"
subtitle: "Methods of Corpus Linguistics (class 6)"
author: "Mariana Montes"
format:
  revealjs:
    preview-links: auto
    multiplex: true
    chalkboard:
        buttons: false
    code-fold: true
    css: styles.css
execute:
  echo: true
from: markdown+emoji
---

```{r}
#| label: setup
#| include: false
headings <- c("Introduction", "Probabilities, odds and logit", "Evaluation", "Interactions", "Random effects") 
library(tidyverse)
library(easystats)
library(kableExtra)
options(digits = 3)
lnplot <- function(df, x, y, title) {
  ggplot(df, aes(x = {{ x }}, y = {{ y }})) +
    geom_line() +
    geom_point() + 
    theme_minimal(base_size = 20) +
    theme(aspect.ratio = 1) +
    labs(title = title)
}
kb_style <- function(df, position = "center", n = 10) {
  df %>% head(n) %>% kbl() %>%
    kable_paper(full_width = FALSE, font_size = 22, position = position)
}
```

## Outline

```{r}
#| label: outline
#| results: asis
#| echo: false
for (heading in headings) {
  cat("-", heading, "\n")
}
i <- 1
```

# `r headings[[i]]`

## Set up code

```{r}
#| label: logistic-code
#| code-fold: false
#| code-line-numbers: "|1|2-5|6-13|14-15|16-17|19-23"
set.seed(2022)
gonna <- tibble(variant = rep("gonna", 50), comp_length = rnorm(50, 6, 0.8),
                register = sample(c("formal", "informal"), 50, replace = TRUE, prob = c(0.1, 0.9)))
going_to <- tibble(variant = rep("going_to", 50), comp_length = rnorm(50, 3, 1.2),
                   register = sample(c("formal", "informal"), 50, replace = TRUE, prob = c(0.7, 0.3)))
gt <- bind_rows(gonna, going_to) %>%
  mutate(
    comp_length = if_else(comp_length > 1, comp_length, 1),
    variant = fct_relevel(variant, "gonna"),
    variant_num = as.numeric(variant)-1,
    register = fct_relevel(register, "informal"),
    source = factor(sample(letters, n(), replace = TRUE))
  )
m1 <- glm(variant ~ comp_length, data = gt, family = binomial(logit))
gt$fit1 <- m1$fitted.values
m2 <- glm(variant ~ comp_length + register, data = gt, family = binomial(logit))
gt$fit2 <- m2$fitted.values

gonna_plot <- ggplot(gt, aes(x = comp_length, y = variant_num)) +
  geom_point(size = 3) + ylim(0, 1) +
  labs(x = "Length of complement", y = "Choice of construction") +
  scale_y_continuous(breaks = c(0, 1), labels = c("gonna", "going to")) +
  theme_minimal(base_size = 20) + theme(aspect.ratio = 1)
```


```{r}
#| label: save-gonna
#| include: false
write_tsv(gt, "gonna_goingto.tsv")
```

::: {.footer}
`r headings[[i]]`
:::

## *gonna* dataset

```{r}
#| label: logistic-data
#| layout-ncol: 2
kb_style(filter(gt, variant == "gonna"), "float_left")
kb_style(filter(gt, variant == "going_to"), "left")
```

::: {.footer}
`r headings[[i]]`
:::

## Scatterplot

What is the relationship between the length of the complement and the choice of *going to/gonna*?

```{r}
#| label: logistic-plot
gonna_plot
```

::: {.footer}
`r headings[[i]]`
:::

## Linear fit {chalkboard-buttons="true"}

The relationship is not linear.

:::: {.columns}

::: {.column width="50%"}
```{r}
#| label: logistic-linear
#| fig-height: 8
gonna_plot + 
  geom_smooth(method = "lm", se = FALSE, color = "darkolivegreen4")
```
:::

::: {.column width="50%" .incremental}
- The residuals are not normally distributed.

- Not all values are possible (probabilities go between 0 and 1).
:::

::::

::: {.footer}
`r headings[[i]]`
:::

## Logistic fit

The fit has an S shape.

```{r}
#| label: logistic-fit
gonna_plot +
  geom_line(aes(y = fit1), color = "goldenrod", size = 2)
```

::: {.footer}
`r headings[[i]]`
:::

## Model

```{r}
#| label: logistic-model
summary(m2)
```

::: {.footer}
`r headings[[i]]`
:::

## Interpretation {.smaller}

```{r}
#| label: interpretation
#| include: false
intercept <- m2$coefficients[[1]] # log odds
cl_lor <- m2$coefficients[["comp_length"]]
reg_lor <- m2$coefficients[["registerformal"]]
```

:::: {.columns}

::: {.column width="35%" .incremental}
### Intercept

- **log odds** of outcome ("going to") when all predictors are at 0 (`comp_length` = 0).

- odds = `exp(`r intercept`)` = `r prettyNum(exp(intercept))`

- prob = odds/(odds+1) $\approx$ `r exp(intercept)/(exp(intercept)+1)`
:::

::: {.column width="65%" .incremental}
### Coefficients

- **log odds ratios**: positive increases chances of "going to", negative of "gonna".

- odds ratio

    + of `comp_length` = `exp(`r cl_lor`)` = `r exp(cl_lor)`
    
    + of `register` = `exp(`r reg_lor`)` = `r exp(reg_lor)`

. . .

> The odds of *going to* vs *gonna* in the formal register are `r exp(reg_lor)` times higher than those in the informal register, other variables being controlled for.

:::

::::

::: {.footer}
`r headings[[i]]`
:::

```{r}
#| label: add-heading1
#| include: false
i <- i+1
```

# `r headings[[i]]`

## Probabilities {.smaller}

:::: {.columns}

::: {.column width="30%"}
###  probs.

- $P$

- 0 - 0.5 - 1

- Number of successes divided by number of trials.
:::

::: {.column width="70%"}

:::

::::

::: {.footer}
`r headings[[i]]`
:::

## Odds {.smaller}

:::: {.columns}

::: {.column width="30%"}
### probs.

- $P$

- 0 - 0.5 - 1

- Number of successes divided by number of trials.
:::


::: {.column width="30%"}
### odds

- $\frac{P}{1-P}$

- 0 - 1 - $\infty$

- Probability of success divided by the probability of failure.

- Undefined for $P=1$.
:::

::: {.column width="30%"}

:::

::::

::: {.footer}
`r headings[[i]]`
:::

## Logit {.smaller}

:::: {.columns}

::: {.column width="30%"}
###  probs.

- $P$

- 0 - 0.5 - 1

- Number of successes divided by number of trials.
:::

::: {.column width="30%"}
### odds

- $\frac{P}{1-P}$

- 0 - 1 - $\infty$

- Probability of success divided by the probability of failure.

- Undefined for $P=1$.
:::

::: {.column width="30%"}
### logit

- $\log\left(\frac{P}{1-P}\right)$

- $-\infty$ - 0 - $\infty$

- If positive, success is more likely; if negative failure is more likely.

- Undefined for $P=0$ and for $P=1$.
:::

::::

::: {.footer}
`r headings[[i]]`
:::

## Simulation

```{r}
#| code-line-numbers: "|3,4,6|8|7,9|10"
#| code-fold: false
#| output-location: column
library(MASS) # to print fractions

probabilities <- c(1/c(7:2),
                   1-(1/c(3:7)))
probs <- tibble(
  P = probabilities,
  P_frac = as.character(fractions(P)),
  odds = P/(1-P),
  odds_frac = as.character(fractions(odds)),
  logit = log(odds)
)
kbl(probs) %>% kable_paper(font_size = 22) %>% 
  row_spec(6, bold = TRUE)
```

::: notes
We'll create a vector `probabilities` with the values of fractions from $\frac{1}{7}$ to $\frac{1}{2}$ and then from $1-\frac{1}{3}$ to $1-\frac{1}{7}$.

`MASS::fractions()` prints them as fractions.

From there we compute odds and logit.
:::

::: {.footer}
`r headings[[i]]`
:::

## Probabilities, odds and logits: plots {visibility="hidden"}

:::: {.columns}

::: {.column width="50%"}
```{r}
#| fig-height: 8
lnplot(probs, P, logit, "logit ~ P")
```
:::

::: {.column width="50%"}
```{r}
#| fig-height: 8
lnplot(probs, P, odds, "odds ~ P")
```
:::

::::

::: {.footer}
`r headings[[i]]`
:::

## Linear vs logistic relationships

Linear relation `logit ~ x` entails logistic curve `p ~ x`.

```{r}
with_x <- tibble(x = 1:30, logit = -3.5 + 0.3*x, odds = exp(logit), P = odds/(1+odds))
```

:::: columns
::: {.column width="50%"}
```{r}
#| fig-height: 8
lnplot(with_x, x, logit, "logit ~ X")
```
:::

::: {.column width="50%"}
```{r}
#| fig-height: 8
lnplot(with_x, x, P, "P ~ X")
```
:::
::::

::: {.footer}
`r headings[[i]]`
:::

```{r}
#| label: add-heading2
#| include: false
i <- i+1
```

# `r headings[[i]]`

## Model

```{r}
#| label: logistic-model2
summary(m2)
```

::: {.footer}
`r headings[[i]]`
:::

## Deviance {.smaller}

Null deviance

:   discrepancy between data and intercept-only model (like SST)

Residual deviance

:   discrepancy between data and fitted model (like SSE)

::: callout-note
### Computation

$-2 \log(L)$ with $L$ the likelihood of encountering the data if the model is true.
:::

AIC (Akaike Information Criterion)

:   corrected residual deviance (to compare models with different N. of predictors) - the smaller the better

Deviance residuals

:   contribution of each observation to the residual deviance.

::: {.footer}
`r headings[[i]]`
:::

## Predicted probability {.smaller}

```{r}
#| label: predicted
#| include: false
pred_logit <- intercept + cl_lor * 4 + reg_lor
```

$$g(x) = \beta_0 + \beta_1x_1 + \beta_2x_2 + ...$$

Let's predict the probability of *going to* when complement length is 4 and register is formal.

. . .

$$g(x) = `r intercept` + `r cl_lor`\times 4 + `r reg_lor` \times 1 = `r pred_logit`$$

. . .

odds = `exp(`r pred_logit`)` = `r exp(pred_logit)`

. . .

$$P(x) = \frac{`r exp(pred_logit)`}{`r exp(pred_logit)` + 1} = `r exp(pred_logit)/(exp(pred_logit)+1)`$$

::: {.footer}
`r headings[[i]]`
:::

## Measures of predictive power {.smaller}

:::: {.columns}

::: {.column width="50%"}
We take all pairs of observations in which the response variable is different (one of *gonna*, one of *going to*).

- `gt0` is what the model predicted for the "gonna" element.

- `gt1` is what the model predicted for the "going to" element.
:::

::: {.column width="50%"}
```{r}
#| label: pred-power
set.seed(0)
pred_power <- tibble(
  gt0 = sample(filter(gt, variant == "gonna")$fit2, 15, replace = FALSE),
  gt1 = sample(filter(gt, variant == "going_to")$fit2, 15, replace = FALSE))
kb_style(pred_power, n = 15)
```
:::

::::

::: {.footer}
`r headings[[i]]`
:::

## C, D, T

:::: {.columns}

::: {.column width="50%"}
- `C` = concordant pair = prediction is higher for "going to" :grin:

- `D` = discordant pair = the prediction is higher for "gonna" :frowning_face:

- `T` = tie = the prediction is the same for both :neutral_face:
:::

::: {.column width="50%"}
```{r}
#| label: pred-power-tbl
pred_power <- pred_power %>%
  mutate(C = gt1 > gt0, D = gt0 > gt1, T = gt1 == gt0)
kb_style(pred_power, n = 15) %>%
  column_spec(3, background = spec_color(pred_power$C, option = "H", begin = 0.8, end = 0.45))
```
:::

::::

::: {.footer}
`r headings[[i]]`
:::

## C-value

```{r}
#| label: pred-power-sum
pred_power <- pred_power %>%
  summarize(C = sum(C), D = sum(D), T = sum(T))
kb_style(pred_power)
```

. . .

$$c = \frac{C+T/2}{C+D+T} = \frac{`r pred_power$C`+`r pred_power$T`/2}{`r pred_power$C`+`r pred_power$D`+`r pred_power$T`} = `r (pred_power$C+pred_power$T/2)/sum(pred_power)`$$

. . .

```{r}
#| label: somers-c
#| code-fold: false
Hmisc::somers2(gt$fit2, gt$variant_num)[["C"]]
```

::: {.footer}
`r headings[[i]]`
:::


## Linear vs logistic regression {.smaller}

| | Linear regression | Logistic regression |
|----------------------|-------------------------|-------------------------|
| Response variable | Numerical | Categorical |
| Relationship between predictor estimate and response | Linear | Logistic^[Linear relationship between estimate and log odds of response.] |
| Fitting function | OSL (ordinary least squares) | MLE (maximum likelihood estimation) |
| Model comparison | F-test  | AIC |
| Evaluation metric | $R^2$ | $C$ |
| Base R function | `lm()` | `glm()` |

::: {.footer}
`r headings[[i]]`
:::

```{r}
#| label: add-heading4
#| include: false
i <- i+1
```

# `r headings[[i]]`

## What is an interaction?

::: msg
When the effect of a predictor depends on the value of another predictor.
:::

Formula: `y ~ x1 + x2 + x1:x2` = `y ~ x1*x2`

::: {.footer}
`r headings[[i]]`
:::

## Examples

Possible interactions of complement length and register (is the text formal or informal?) on choice of *gonna*.

- The effect of complement length is also positive/negative but stronger/weaker when texts are informal.

- The effect of complement length is positive/negative when texts are informal, reversed when texts are formal.

::: {.footer}
`r headings[[i]]`
:::

## Model with interactions {.smaller}

:::: {.columns}

::: {.column width="60%"}
```{r}
#| label: interactions
#| code-fold: false
m3 <- glm(variant ~ comp_length*register, data = gt, family = binomial(logit))
summary(m3)
```
:::

::: {.column width="40%"}
### Interpretation

- Intercept is interpreted in the same way.

- `comp_length` is the effect of complement length *in informal register*.

- `registerformal` is the effect of the formal register at *0 complement length*.

- `comp_length:registerformal` is the difference in the effect of complement length in formal register, compared to informal register.

:::

::::

::: {.footer}
`r headings[[i]]`
:::

## Visualization

```{r}
#| label: ggeffects
library(ggeffects)
plot(ggpredict(m3, c("comp_length", "register")))
```

::: {.footer}
`r headings[[i]]`
:::

```{r}
#| label: add-heading5
#| include: false
i <- i+1
```

# `r headings[[i]]`

## Fixed vs random effects

Unlike **fixed effects** (what we have dealt with up to now), **random effects**:

- May not be replicable in a different dataset.

- Involve a *sample* of the possible values in the population.

Examples: speaker, lexical effects, topic... &rarr; often operationalized as *filename*.

::: {.footer}
`r headings[[i]]`
:::

## Random intercept

::: msg
The intercept can vary.
:::

. . .

- Different individuals prefer *gonna* over *going to* regardless of complement length.

- Certain children always produce longer utterances than others of the same age.

. . .

::: callout-important
### Nested random intercept

E.g. random intercept for filename *and* random intercept for register; each filename occurs in only one register.
:::

::: {.footer}
`r headings[[i]]`
:::

## Random slope

::: msg
The slope of a fixed effect can vary.
:::

A given predictor can have different effects in different texts.

. . .

- Complement length is more influential in the choice of *gonna* for some individuals than for others.

- For certain children, utterance length increases with age at a higher pace than of others.

::: {.footer}
`r headings[[i]]`
:::

## How to

- `lme4::glmer()` instead of `glm()`; `lme4::lmer()` instead of `lm()`.

    + The `control` argument helps us deal with convergence issues.

. . .

- Extension of the R formula:

    + `(1 | filename)` for `filename` as random effect.
    
    + `(age | child)` for `child` as a random slope for `age`.
    
::: {.footer}
`r headings[[i]]`
:::

## Model with random effects

```{r}
#| label: mixed
#| code-fold: false
m4 <- lme4::glmer(variant ~ comp_length*register + (1 | source), data = gt, family = binomial)
summary(m4)
```

::: {.footer}
`r headings[[i]]`
:::

## Compare models

```{r}
#| label: performance
performance::compare_performance(m1, m2, m3, m4, metrics = "AIC")
```

::: {.footer}
`r headings[[i]]`
:::

# Next: Correspondence Analysis